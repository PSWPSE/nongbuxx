#!/usr/bin/env python3

from flask import Flask, request, jsonify, send_from_directory, abort
from flask_cors import CORS
import os
import traceback
import logging
import time
from datetime import datetime
from pathlib import Path
import json
import uuid
from dotenv import load_dotenv

# Load environment variables from env.local file
load_dotenv('env.local')

from url_extractor import OptimizedNewsExtractor
from nongbuxx_generator import NongbuxxGenerator

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize Flask app with frontend as static folder
app = Flask(__name__, static_folder='frontend', static_url_path='/static')

# CORS configuration for production deployment
CORS(app, origins=[
    "http://localhost:3000",  # Local development
    "http://localhost:5000",  # Local development 
    "http://localhost:8080",  # Local development
    "https://nongbuxxfrontend.vercel.app",  # Main production frontend domain
    "https://nongbuxxfrontend-dsvsdvsdvsds-projects.vercel.app",  # Project-specific domain
    "https://nongbuxxfrontend-fgvw3eory-dsvsdvsdvsds-projects.vercel.app",  # New deployment URL
    "https://nongbuxx.vercel.app",  # Alternative domain
    "https://nongbuxx-frontend.vercel.app",  # Alternative domain
], allow_headers=["Content-Type", "Authorization", "Accept"], methods=["GET", "POST", "OPTIONS"], supports_credentials=False)

# Configuration
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size
app.config['UPLOAD_FOLDER'] = 'uploads'

# Create necessary directories
os.makedirs('uploads', exist_ok=True)
os.makedirs('generated_content', exist_ok=True)

# Store active jobs in memory (for production, use Redis or database)
active_jobs = {}

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return send_from_directory('frontend', 'index.html')

# ì •ì  íŒŒì¼ì€ Flaskê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (static_folder ì„¤ì •)

@app.route('/favicon.ico')
def favicon():
    """favicon ìš”ì²­ ì²˜ë¦¬"""
    return '', 204  # No Content ì‘ë‹µìœ¼ë¡œ favicon ìš”ì²­ ë¬´ì‹œ

@app.route('/api/health', methods=['GET', 'OPTIONS'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, Accept'
        return response
    
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })

@app.route('/api/validate-key', methods=['POST', 'OPTIONS'])
def validate_api_key():
    """API í‚¤ ìœ íš¨ì„± ê²€ì¦ ì—”ë“œí¬ì¸íŠ¸"""
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, Accept'
        return response
    
    try:
        data = request.get_json()
        
        if not data or 'api_provider' not in data or 'api_key' not in data:
            return jsonify({
                'success': False,
                'error': 'API provider and API key are required',
                'code': 'MISSING_PARAMETERS'
            }), 400
        
        api_provider = data['api_provider']
        api_key = data['api_key']
        
        if api_provider not in ['anthropic', 'openai']:
            return jsonify({
                'success': False,
                'error': 'API provider must be anthropic or openai',
                'code': 'INVALID_API_PROVIDER'
            }), 400
        
        if not api_key or len(api_key.strip()) < 10:
            return jsonify({
                'success': False,
                'error': 'Invalid API key format',
                'code': 'INVALID_API_KEY'
            }), 400
        
        # API í‚¤ í˜•ì‹ ê¸°ë³¸ ê²€ì¦
        if api_provider == 'anthropic':
            if not api_key.startswith('sk-ant-'):
                return jsonify({
                    'success': False,
                    'error': 'Invalid Anthropic API key format',
                    'code': 'INVALID_ANTHROPIC_KEY'
                }), 400
        elif api_provider == 'openai':
            if not api_key.startswith('sk-'):
                return jsonify({
                    'success': False,
                    'error': 'Invalid OpenAI API key format',
                    'code': 'INVALID_OPENAI_KEY'
                }), 400
        
        # ì‹¤ì œ API í˜¸ì¶œì„ í†µí•œ ìœ íš¨ì„± ê²€ì¦
        try:
            if api_provider == 'anthropic':
                import anthropic
                client = anthropic.Anthropic(api_key=api_key)
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ë¡œ ìœ íš¨ì„± í™•ì¸
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=10,
                    messages=[{"role": "user", "content": "Hello"}]
                )
                
            elif api_provider == 'openai':
                import openai
                client = openai.OpenAI(api_key=api_key)
                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ìœ íš¨ì„± í™•ì¸
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    max_tokens=10,
                    messages=[{"role": "user", "content": "Hello"}]
                )
            
            return jsonify({
                'success': True,
                'message': 'API key is valid',
                'provider': api_provider
            })
            
        except Exception as e:
            error_msg = str(e)
            if 'Incorrect API key' in error_msg or 'Invalid API key' in error_msg:
                return jsonify({
                    'success': False,
                    'error': 'Invalid API key',
                    'code': 'INVALID_API_KEY'
                }), 401
            elif 'exceeded' in error_msg.lower():
                return jsonify({
                    'success': False,
                    'error': 'API rate limit exceeded',
                    'code': 'RATE_LIMIT_EXCEEDED'
                }), 429
            else:
                return jsonify({
                    'success': False,
                    'error': f'API validation failed: {error_msg}',
                    'code': 'API_VALIDATION_FAILED'
                }), 400
                
    except Exception as e:
        logger.error(f"API key validation error: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'code': 'INTERNAL_ERROR'
        }), 500

@app.route('/api/generate', methods=['POST', 'OPTIONS'])
def generate_content():
    """
    ì½˜í…ì¸  ìƒì„± API
    
    Request Body:
    {
        "url": "https://example.com/news",
        "api_provider": "anthropic",  // required: anthropic or openai
        "api_key": "sk-...",         // required: user's API key
        "filename": "custom_name",    // optional
        "save_intermediate": true,    // optional
        "content_type": "standard"    // optional: 'standard' or 'blog'
    }
    """
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, Accept'
        return response
    
    try:
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = request.get_json()
        
        if not data or 'url' not in data:
            return jsonify({
                'success': False,
                'error': 'URL is required',
                'code': 'MISSING_URL'
            }), 400
        
        # í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸
        required_fields = ['url', 'api_provider', 'api_key']
        for field in required_fields:
            if field not in data or not data[field]:
                return jsonify({
                    'success': False,
                    'error': f'{field} is required',
                    'code': f'MISSING_{field.upper()}'
                }), 400
        
        url = data['url']
        api_provider = data['api_provider']
        api_key = data['api_key']
        custom_filename = data.get('filename')
        save_intermediate = data.get('save_intermediate', False)
        content_type = data.get('content_type', 'standard')  # ê¸°ë³¸ê°’ì€ 'standard'
        
        # URL ê¸°ë³¸ ê²€ì¦
        if not url.startswith(('http://', 'https://')):
            return jsonify({
                'success': False,
                'error': 'Invalid URL format',
                'code': 'INVALID_URL'
            }), 400
        
        # API ì œê³µì ê²€ì¦
        if api_provider not in ['anthropic', 'openai']:
            return jsonify({
                'success': False,
                'error': 'API provider must be anthropic or openai',
                'code': 'INVALID_API_PROVIDER'
            }), 400
        
        # ì½˜í…ì¸  íƒ€ì… ê²€ì¦
        if content_type not in ['standard', 'blog']:
            return jsonify({
                'success': False,
                'error': 'Content type must be standard or blog',
                'code': 'INVALID_CONTENT_TYPE'
            }), 400
        
        # API í‚¤ ê¸°ë³¸ í˜•ì‹ ê²€ì¦
        if api_provider == 'anthropic' and not api_key.startswith('sk-ant-'):
            return jsonify({
                'success': False,
                'error': 'Invalid Anthropic API key format',
                'code': 'INVALID_ANTHROPIC_KEY'
            }), 400
        elif api_provider == 'openai' and not api_key.startswith('sk-'):
            return jsonify({
                'success': False,
                'error': 'Invalid OpenAI API key format',
                'code': 'INVALID_OPENAI_KEY'
            }), 400
        
        # ì‘ì—… ID ìƒì„±
        job_id = str(uuid.uuid4())
        active_jobs[job_id] = {
            'status': 'processing',
            'url': url,
            'content_type': content_type,
            'started_at': datetime.now().isoformat(),
            'progress': 0
        }
        
        logger.info(f"Starting content generation for URL: {url} (Job ID: {job_id}, Type: {content_type})")
        
        # NONGBUXX ìƒì„±ê¸° ì´ˆê¸°í™” (ì‚¬ìš©ì ì œê³µ API í‚¤ ì‚¬ìš©)
        generator = NongbuxxGenerator(
            api_provider=api_provider,
            api_key=api_key,
            save_intermediate=save_intermediate
        )
        
        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        active_jobs[job_id]['progress'] = 25
        active_jobs[job_id]['status'] = 'extracting'
        
        # ì½˜í…ì¸  ìƒì„± (ì½˜í…ì¸  íƒ€ì… ì „ë‹¬)
        result = generator.generate_content(url, custom_filename, content_type)
        
        # ì •ë¦¬
        generator.cleanup()
        
        if result['success']:
            # ìƒì„±ëœ íŒŒì¼ ì½ê¸°
            with open(result['output_file'], 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ì‘ì—… ì™„ë£Œ ì²˜ë¦¬
            active_jobs[job_id].update({
                'status': 'completed',
                'progress': 100,
                'completed_at': datetime.now().isoformat(),
                'output_file': str(result['output_file']),
                'title': result['title'],
                'content_type': result['content_type']
            })
            
            logger.info(f"Content generation completed for job {job_id} (Type: {content_type})")
            
            return jsonify({
                'success': True,
                'job_id': job_id,
                'data': {
                    'title': result['title'],
                    'content': content,
                    'output_file': str(result['output_file']),
                    'timestamp': result['timestamp'],
                    'url': url,
                    'api_provider': api_provider,
                    'content_type': result['content_type']
                }
            })
        else:
            # ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬
            active_jobs[job_id].update({
                'status': 'failed',
                'error': result['error'],
                'completed_at': datetime.now().isoformat()
            })
            
            logger.error(f"Content generation failed for job {job_id}: {result['error']}")
            
            # ì—ëŸ¬ ë©”ì‹œì§€ì— ë”°ë¼ ì ì ˆí•œ HTTP ìƒíƒœ ì½”ë“œ ë°˜í™˜
            error_msg = result['error']
            if 'ì°¨ë‹¨' in error_msg or '403' in error_msg:
                # ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì ‘ê·¼ì„ ì°¨ë‹¨í•œ ê²½ìš°
            return jsonify({
                'success': False,
                'job_id': job_id,
                    'error': error_msg,
                    'code': 'ACCESS_BLOCKED'
                }), 403
            elif 'ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' in error_msg or '404' in error_msg:
                # í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
                return jsonify({
                    'success': False,
                    'job_id': job_id,
                    'error': error_msg,
                    'code': 'PAGE_NOT_FOUND'
                }), 404
            else:
                # ê¸°íƒ€ ì˜¤ë¥˜
                return jsonify({
                    'success': False,
                    'job_id': job_id,
                    'error': error_msg,
                'code': 'GENERATION_FAILED'
            }), 500
            
    except Exception as e:
        logger.error(f"Content generation error: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'code': 'INTERNAL_ERROR'
        }), 500

@app.route('/api/status/<job_id>', methods=['GET'])
def get_job_status(job_id):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    if job_id not in active_jobs:
        return jsonify({
            'success': False,
            'error': 'Job not found',
            'code': 'JOB_NOT_FOUND'
        }), 404
    
    job_info = active_jobs[job_id]
    return jsonify({
        'success': True,
        'job_id': job_id,
        'status': job_info['status'],
        'progress': job_info['progress'],
        'started_at': job_info['started_at'],
        'completed_at': job_info.get('completed_at'),
        'error': job_info.get('error')
    })

@app.route('/api/download/<job_id>', methods=['GET'])
def download_file(job_id):
    """ìƒì„±ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    if job_id not in active_jobs:
        return jsonify({
            'success': False,
            'error': 'Job not found',
            'code': 'JOB_NOT_FOUND'
        }), 404
    
    job_info = active_jobs[job_id]
    
    if job_info['status'] != 'completed':
        return jsonify({
            'success': False,
            'error': 'Job not completed',
            'code': 'JOB_NOT_COMPLETED'
        }), 400
    
    file_path = Path(job_info['output_file'])
    if not file_path.exists():
        return jsonify({
            'success': False,
            'error': 'File not found',
            'code': 'FILE_NOT_FOUND'
        }), 404
    
    return send_from_directory(
        file_path.parent,
        file_path.name,
        as_attachment=True,
        mimetype='text/markdown'
    )

@app.route('/api/batch-generate', methods=['POST', 'OPTIONS'])
def batch_generate():
    """
    ë°°ì¹˜ ì½˜í…ì¸  ìƒì„± API
    
    Request Body:
    {
        "urls": ["https://example1.com", "https://example2.com"],
        "api_provider": "anthropic",  // required: anthropic or openai
        "api_key": "sk-...",         // required: user's API key
        "save_intermediate": false,   // optional
        "content_type": "standard"    // optional: 'standard' or 'blog'
    }
    """
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, Accept'
        return response
    
    try:
        data = request.get_json()
        
        if not data or 'urls' not in data:
            return jsonify({
                'success': False,
                'error': 'URLs are required',
                'code': 'MISSING_URLS'
            }), 400
        
        # API í‚¤ ê²€ì¦
        if 'api_provider' not in data or 'api_key' not in data:
            return jsonify({
                'success': False,
                'error': 'API provider and API key are required',
                'code': 'MISSING_API_CREDENTIALS'
            }), 400
        
        urls = data['urls']
        api_provider = data['api_provider']
        api_key = data['api_key']
        save_intermediate = data.get('save_intermediate', False)
        content_type = data.get('content_type', 'standard')  # ê¸°ë³¸ê°’ì€ 'standard'
        
        if not isinstance(urls, list) or len(urls) == 0:
            return jsonify({
                'success': False,
                'error': 'URLs must be a non-empty list',
                'code': 'INVALID_URLS'
            }), 400
        
        if api_provider not in ['anthropic', 'openai']:
            return jsonify({
                'success': False,
                'error': 'API provider must be anthropic or openai',
                'code': 'INVALID_API_PROVIDER'
            }), 400
        
        # ì½˜í…ì¸  íƒ€ì… ê²€ì¦
        if content_type not in ['standard', 'blog']:
            return jsonify({
                'success': False,
                'error': 'Content type must be standard or blog',
                'code': 'INVALID_CONTENT_TYPE'
            }), 400
        
        # ë°°ì¹˜ ì‘ì—… ID ìƒì„±
        batch_job_id = str(uuid.uuid4())
        active_jobs[batch_job_id] = {
            'status': 'processing',
            'type': 'batch',
            'urls': urls,
            'content_type': content_type,
            'started_at': datetime.now().isoformat(),
            'progress': 0,
            'results': []
        }
        
        logger.info(f"Starting batch generation for {len(urls)} URLs (Job ID: {batch_job_id}, Type: {content_type})")
        
        # NONGBUXX ìƒì„±ê¸° ì´ˆê¸°í™” (ì‚¬ìš©ì API í‚¤ ì‚¬ìš©)
        generator = NongbuxxGenerator(
            api_provider=api_provider,
            api_key=api_key,  # ì‚¬ìš©ì API í‚¤ ì „ë‹¬
            save_intermediate=save_intermediate
        )
        
        # ë°°ì¹˜ ì²˜ë¦¬ (ì½˜í…ì¸  íƒ€ì… ì „ë‹¬)
        results = generator.batch_generate(urls, content_type=content_type)
        
        # ì •ë¦¬
        generator.cleanup()
        
        # ê²°ê³¼ ì²˜ë¦¬
        processed_results = []
        for result in results:
            if result['success']:
                with open(result['output_file'], 'r', encoding='utf-8') as f:
                    content = f.read()
                
                processed_results.append({
                    'success': True,
                    'url': result['url'],
                    'title': result['title'],
                    'content': content,
                    'output_file': str(result['output_file']),
                    'timestamp': result['timestamp'],
                    'content_type': result['content_type']
                })
            else:
                processed_results.append({
                    'success': False,
                    'url': result['url'],
                    'error': result['error']
                })
        
        # ì„±ê³µ í†µê³„
        success_count = sum(1 for r in processed_results if r['success'])
        
        # ì‘ì—… ì™„ë£Œ ì²˜ë¦¬
        active_jobs[batch_job_id].update({
            'status': 'completed',
            'progress': 100,
            'completed_at': datetime.now().isoformat(),
            'results': processed_results,
            'success_count': success_count,
            'total_count': len(urls)
        })
        
        logger.info(f"Batch generation completed for job {batch_job_id}: {success_count}/{len(urls)} successful (Type: {content_type})")
        
        return jsonify({
            'success': True,
            'job_id': batch_job_id,
            'data': {
                'results': processed_results,
                'success_count': success_count,
                'total_count': len(urls),
                'api_provider': api_provider,
                'content_type': content_type
            }
        })
        
    except Exception as e:
        logger.error(f"Batch generation error: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'code': 'INTERNAL_ERROR'
        }), 500

@app.route('/api/extract-news-links', methods=['POST', 'OPTIONS'])
def extract_news_links():
    """
    ë‰´ìŠ¤ ë§í¬ ì¶”ì¶œ API (ë‹¤ì¤‘ ì¶œì²˜ ì§€ì›)
    
    Request Body:
    {
        "keyword": "Tesla AI",           // optional: ê²€ìƒ‰ í‚¤ì›Œë“œ
        "count": 10,                    // optional: ì¶”ì¶œí•  ë‰´ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸ê°’: 10)
        "sources": ["yahoo_finance"]     // optional: ì¶œì²˜ ID ë°°ì—´ (ê¸°ë³¸ê°’: í™œì„±í™”ëœ ëª¨ë“  ì¶œì²˜)
    }
    """
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, Accept'
        return response
    
    try:
        data = request.get_json() or {}
        
        keyword = data.get('keyword', '').strip()
        count = data.get('count', 10)
        requested_sources = data.get('sources', [])
        
        # ì…ë ¥ê°’ ê²€ì¦
        if count < 1 or count > 50:
            return jsonify({
                'success': False,
                'error': 'ë‰´ìŠ¤ ê°œìˆ˜ëŠ” 1~50ê°œ ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.',
                'code': 'INVALID_COUNT'
            }), 400
        
        # ì‚¬ìš©í•  ì¶œì²˜ ê²°ì • (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)
        available_sources = get_all_extractable_sources()  # ì„œë¸Œì¹´í…Œê³ ë¦¬ í¬í•¨
        
        if requested_sources:
            # ìš”ì²­ëœ ì¶œì²˜ë§Œ ì‚¬ìš©
            selected_sources = [s for s in available_sources if s['id'] in requested_sources and s.get('active', True)]
            if not selected_sources:
                return jsonify({
                    'success': False,
                    'error': 'ìš”ì²­ëœ ì¶œì²˜ ì¤‘ í™œì„±í™”ëœ ì¶œì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.',
                    'code': 'NO_ACTIVE_SOURCES'
                }), 400
        else:
            # í™œì„±í™”ëœ ëª¨ë“  ì¶œì²˜ ì‚¬ìš©
            selected_sources = [s for s in available_sources if s.get('active', True)]
            if not selected_sources:
                return jsonify({
                    'success': False,
                    'error': 'í™œì„±í™”ëœ ì¶œì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.',
                    'code': 'NO_ACTIVE_SOURCES'
                }), 400
        
        logger.info(f"Starting multi-source news extraction - keyword: '{keyword}', count: {count}, sources: {[s['id'] for s in selected_sources]}")
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë‰´ìŠ¤ ì¶”ì¶œ (ì„±ëŠ¥ ìµœì í™”)
        from url_extractor import extract_news_from_multiple_sources
        
        logger.info(f"ë³‘ë ¬ ë‰´ìŠ¤ ì¶”ì¶œ ì‹œì‘: {len(selected_sources)}ê°œ ì¶œì²˜")
        start_time = time.time()
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëª¨ë“  ì¶œì²˜ì—ì„œ ë™ì‹œì— ë‰´ìŠ¤ ì¶”ì¶œ
        all_news_items = extract_news_from_multiple_sources(
            sources=selected_sources,
            keyword=keyword,
            count=count,
            max_workers=min(len(selected_sources), 3)  # ìµœëŒ€ 3ê°œ ë™ì‹œ ì²˜ë¦¬
        )
        
        end_time = time.time()
        logger.info(f"ë³‘ë ¬ ì¶”ì¶œ ì™„ë£Œ: {len(all_news_items)}ê°œ ë‰´ìŠ¤, ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        
        # ì¶œì²˜ë³„ ê²°ê³¼ í†µê³„
        source_results = []
        source_counts = {}
        
        for item in all_news_items:
            source_id = item.get('source_id')
            if source_id:
                source_counts[source_id] = source_counts.get(source_id, 0) + 1
        
        for source in selected_sources:
            count_extracted = source_counts.get(source['id'], 0)
            source_results.append({
                'source_id': source['id'],
                'source_name': source['name'],
                'count': count_extracted,
                'success': count_extracted > 0
            })
            
            if count_extracted > 0:
                logger.info(f"âœ… {source['name']}: {count_extracted}ê°œ ë‰´ìŠ¤ ì¶”ì¶œ")
            else:
                logger.warning(f"âŒ {source['name']}: ë‰´ìŠ¤ ì¶”ì¶œ ì‹¤íŒ¨")
        
        # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
        unique_news = []
        seen_urls = set()
        
        for item in all_news_items:
            if item['url'] not in seen_urls:
                unique_news.append(item)
                seen_urls.add(item['url'])
        
        # ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
        if not unique_news:
            return jsonify({
                'success': False,
                'error': f"'{keyword}' í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if keyword else 'ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                'code': 'NO_NEWS_FOUND',
                'source_results': source_results
            }), 404
        
        # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°)
        if keyword:
            keyword_lower = keyword.lower()
            unique_news.sort(key=lambda x: (
                keyword_lower in x['title'].lower(),
                sum(1 for kw in x.get('keywords', []) if keyword_lower in kw.lower())
            ), reverse=True)
        
        logger.info(f"Multi-source news extraction completed: {len(unique_news)} unique articles from {len(selected_sources)} sources")
        
        return jsonify({
            'success': True,
            'data': {
                'keyword': keyword,
                'count': len(unique_news),
                'total_extracted': len(all_news_items),
                'unique_count': len(unique_news),
                'news_items': unique_news,
                'source_results': source_results
            }
        })
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Multi-source news extraction error: {error_msg}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'success': False,
            'error': f'ë‰´ìŠ¤ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'EXTRACTION_ERROR'
        }), 500

def extract_news_from_source(source, keyword, count):
    """íŠ¹ì • ì¶œì²˜ì—ì„œ ë‰´ìŠ¤ ì¶”ì¶œ (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)"""
    try:
        # ëª¨ë“  ì¶œì²˜ì— ëŒ€í•´ ìµœì í™”ëœ ì¶”ì¶œê¸° ì‚¬ìš©
        from url_extractor import OptimizedNewsExtractor
        
        # ì‹¤ì œ ì¶”ì¶œ URL ê²°ì • (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)
        extraction_url = source.get('full_url', source['url'])
        
        logger.info(f"Extracting news from {source['name']}")
        logger.info(f"Extraction URL: {extraction_url}")
        
        extractor = OptimizedNewsExtractor(
            base_url=extraction_url,
            search_keywords=keyword if keyword else None,
            max_news=count
        )
        
        return extractor.extract_news()
            
    except Exception as e:
        logger.error(f"Error extracting news from {source['name']}: {str(e)}")
        raise e

# ============================================================================
# ì¶œì²˜ ê´€ë¦¬ API
# ============================================================================

def load_sources():
    """ì¶œì²˜ ì •ë³´ë¥¼ JSON íŒŒì¼ì—ì„œ ë¡œë“œ (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)"""
    sources_file = Path('data/sources.json')
    try:
        if sources_file.exists():
            with open(sources_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('sources', [])
        else:
            # ê¸°ë³¸ ì¶œì²˜ ë°ì´í„°ë¡œ íŒŒì¼ ìƒì„±
            default_sources = [{
                "id": "yahoo_finance",
                "name": "Yahoo Finance",
                "url": "https://finance.yahoo.com/topic/latest-news/",
                "parser_type": "yahoo_finance",
                "active": True,
                "description": "ê¸€ë¡œë²Œ ê¸ˆìœµ ë‰´ìŠ¤ ë° ì‹œì¥ ì •ë³´",
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }]
            save_sources(default_sources)
            return default_sources
    except Exception as e:
        logger.error(f"Failed to load sources: {e}")
        return []

def save_sources(sources):
    """ì¶œì²˜ ì •ë³´ë¥¼ JSON íŒŒì¼ì— ì €ì¥"""
    sources_file = Path('data/sources.json')
    try:
        # data ë””ë ‰í† ë¦¬ ìƒì„±
        sources_file.parent.mkdir(exist_ok=True)
        
        data = {
            "sources": sources,
            "updated_at": datetime.now().isoformat()
        }
        
        with open(sources_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        logger.error(f"Failed to save sources: {e}")
        return False

def find_source_by_id(source_id):
    """IDë¡œ ì¶œì²˜ ì°¾ê¸° (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)"""
    sources = load_sources()
    
    # ë¶€ëª¨ ì¶œì²˜ì—ì„œ ì°¾ê¸°
    for source in sources:
        if source['id'] == source_id:
            return source
            
        # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ì—ì„œ ì°¾ê¸°
        if 'subcategories' in source:
            for subcategory in source['subcategories']:
                if subcategory['id'] == source_id:
                    # ë¶€ëª¨ URLê³¼ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ URL ê²°í•©
                    subcategory_copy = subcategory.copy()
                    subcategory_copy['full_url'] = source['url'].rstrip('/') + subcategory['url']
                    subcategory_copy['parent_id'] = source['id']
                    subcategory_copy['parent_name'] = source['name']
                    return subcategory_copy
    
    return None

def get_all_extractable_sources():
    """ì¶”ì¶œ ê°€ëŠ¥í•œ ëª¨ë“  ì¶œì²˜ ë°˜í™˜ (ì„œë¸Œ ì¹´í…Œê³ ë¦¬ í¬í•¨)"""
    sources = load_sources()
    extractable_sources = []
    
    for source in sources:
        if source.get('is_parent', False):
            # ë¶€ëª¨ ì¶œì²˜ì¸ ê²½ìš° ì„œë¸Œ ì¹´í…Œê³ ë¦¬ë“¤ ì¶”ê°€
            if 'subcategories' in source:
                for subcategory in source['subcategories']:
                    if subcategory.get('active', True):
                        subcategory_copy = subcategory.copy()
                        subcategory_copy['full_url'] = source['url'].rstrip('/') + subcategory['url']
                        subcategory_copy['parent_id'] = source['id']
                        subcategory_copy['parent_name'] = source['name']
                        extractable_sources.append(subcategory_copy)
        else:
            # ë‹¨ë… ì¶œì²˜ì¸ ê²½ìš°
            if source.get('active', True):
                extractable_sources.append(source)
    
    return extractable_sources

def validate_source_data(data):
    """ì¶œì²˜ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
    required_fields = ['name', 'url']
    for field in required_fields:
        if not data.get(field):
            return False, f'{field} is required'
    
    # URL ìœ íš¨ì„± ê²€ì¦
    url = data.get('url', '')
    if not url.startswith(('http://', 'https://')):
        return False, 'Invalid URL format'
    
    return True, None

@app.route('/api/sources/extractable', methods=['GET'])
def get_extractable_sources():
    """ì¶”ì¶œ ê°€ëŠ¥í•œ ì¶œì²˜ ëª©ë¡ ì¡°íšŒ (ì„œë¸Œ ì¹´í…Œê³ ë¦¬ í¬í•¨)"""
    try:
        extractable_sources = get_all_extractable_sources()
        
        return jsonify({
            'success': True,
            'data': {
                'sources': extractable_sources,
                'total_count': len(extractable_sources)
            }
        })
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to get extractable sources: {error_msg}")
        
        return jsonify({
            'success': False,
            'error': f'ì¶”ì¶œ ê°€ëŠ¥í•œ ì¶œì²˜ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'EXTRACTABLE_SOURCES_ERROR'
        }), 500

@app.route('/api/sources', methods=['GET', 'OPTIONS'])
def get_sources():
    """ëª¨ë“  ì¶œì²˜ ì¡°íšŒ"""
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, PUT, DELETE, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, Accept'
        return response
    
    try:
        sources = load_sources()
        
        return jsonify({
            'success': True,
            'data': {
                'sources': sources,
                'total_count': len(sources)
            }
        })
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to get sources: {error_msg}")
        
        return jsonify({
            'success': False,
            'error': f'ì¶œì²˜ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'SOURCES_LOAD_ERROR'
        }), 500

@app.route('/api/sources', methods=['POST'])
def create_source():
    """ìƒˆ ì¶œì²˜ ë“±ë¡ (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'Request data is required',
                'code': 'MISSING_DATA'
            }), 400
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        is_valid, error_msg = validate_source_data(data)
        if not is_valid:
            return jsonify({
                'success': False,
                'error': error_msg,
                'code': 'INVALID_DATA'
            }), 400
        
        # ê¸°ì¡´ ì¶œì²˜ ë¡œë“œ
        sources = load_sources()
        
        # ê³ ìœ  ID ìƒì„±
        source_id = data.get('id') or f"source_{uuid.uuid4().hex[:8]}"
        
        # ID ì¤‘ë³µ í™•ì¸
        if any(source['id'] == source_id for source in sources):
            return jsonify({
                'success': False,
                'error': 'Source ID already exists',
                'code': 'DUPLICATE_ID'
            }), 400
        
        # ìƒˆ ì¶œì²˜ ê°ì²´ ìƒì„±
        new_source = {
            'id': source_id,
            'name': data['name'],
            'url': data['url'],
            'is_parent': data.get('is_parent', False),
            'active': data.get('active', True),
            'description': data.get('description', ''),
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        # ë‹¨ë… ì¶œì²˜ì¸ ê²½ìš°ì—ë§Œ parser_type ì¶”ê°€
        if not new_source['is_parent']:
            new_source['parser_type'] = data.get('parser_type', 'generic')
        
        # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ê°€ (ë¶€ëª¨ ì¶œì²˜ì¸ ê²½ìš°)
        if new_source['is_parent'] and 'subcategories' in data:
            new_source['subcategories'] = []
            for subcategory in data['subcategories']:
                subcategory_obj = {
                    'id': subcategory.get('id') or f"sub_{uuid.uuid4().hex[:8]}",
                    'name': subcategory['name'],
                    'url': subcategory['url'],
                    'parser_type': subcategory.get('parser_type', 'universal'),
                    'active': subcategory.get('active', True),
                    'description': subcategory.get('description', ''),
                    'created_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat()
                }
                new_source['subcategories'].append(subcategory_obj)
        
        # ì¶œì²˜ ëª©ë¡ì— ì¶”ê°€
        sources.append(new_source)
        
        # ì €ì¥
        if save_sources(sources):
            logger.info(f"New source created: {source_id} - {new_source['name']}")
            
            return jsonify({
                'success': True,
                'data': new_source,
                'message': 'ì¶œì²˜ê°€ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }), 201
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to save source',
                'code': 'SAVE_ERROR'
            }), 500
            
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to create source: {error_msg}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'success': False,
            'error': f'ì¶œì²˜ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'CREATE_SOURCE_ERROR'
        }), 500

@app.route('/api/sources/<source_id>', methods=['GET', 'OPTIONS'])
def get_source(source_id):
    """íŠ¹ì • ì¶œì²˜ ì¡°íšŒ"""
    if request.method == 'OPTIONS':
        response = jsonify({})
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, PUT, DELETE, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization, Accept'
        return response
    
    try:
        source = find_source_by_id(source_id)
        
        if not source:
            return jsonify({
                'success': False,
                'error': 'Source not found',
                'code': 'SOURCE_NOT_FOUND'
            }), 404
        
        return jsonify({
            'success': True,
            'data': source
        })
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to get source {source_id}: {error_msg}")
        
        return jsonify({
            'success': False,
            'error': f'ì¶œì²˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'GET_SOURCE_ERROR'
        }), 500

@app.route('/api/sources/<source_id>', methods=['PUT'])
def update_source(source_id):
    """ì¶œì²˜ ìˆ˜ì •"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'Request data is required',
                'code': 'MISSING_DATA'
            }), 400
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        is_valid, error_msg = validate_source_data(data)
        if not is_valid:
            return jsonify({
                'success': False,
                'error': error_msg,
                'code': 'INVALID_DATA'
            }), 400
        
        # ê¸°ì¡´ ì¶œì²˜ ë¡œë“œ
        sources = load_sources()
        
        # ì¶œì²˜ ì°¾ê¸°
        source_index = next((i for i, source in enumerate(sources) if source['id'] == source_id), None)
        
        if source_index is None:
            return jsonify({
                'success': False,
                'error': 'Source not found',
                'code': 'SOURCE_NOT_FOUND'
            }), 404
        
        # ì¶œì²˜ ì •ë³´ ì—…ë°ì´íŠ¸
        existing_source = sources[source_index]
        updated_source = {
            **existing_source,
            'name': data['name'],
            'url': data['url'],
            'parser_type': data.get('parser_type', existing_source.get('parser_type', 'generic')),
            'active': data.get('active', existing_source.get('active', True)),
            'description': data.get('description', existing_source.get('description', '')),
            'updated_at': datetime.now().isoformat()
        }
        
        sources[source_index] = updated_source
        
        # ì €ì¥
        if save_sources(sources):
            logger.info(f"Source updated: {source_id} - {updated_source['name']}")
            
            return jsonify({
                'success': True,
                'data': updated_source,
                'message': 'ì¶œì²˜ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to save source',
                'code': 'SAVE_ERROR'
            }), 500
            
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to update source {source_id}: {error_msg}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'success': False,
            'error': f'ì¶œì²˜ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'UPDATE_SOURCE_ERROR'
        }), 500

@app.route('/api/sources/<source_id>', methods=['DELETE'])
def delete_source(source_id):
    """ì¶œì²˜ ì‚­ì œ (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)"""
    try:
        # ê¸°ì¡´ ì¶œì²˜ ë¡œë“œ
        sources = load_sources()
        
        # ì¶œì²˜ ì°¾ê¸° (ë¶€ëª¨ ì¶œì²˜ ë° ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ê²€ìƒ‰)
        source_index = None
        parent_index = None
        subcategory_index = None
        
        for i, source in enumerate(sources):
            if source['id'] == source_id:
                source_index = i
                break
            
            # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ì—ì„œ ì°¾ê¸°
            if 'subcategories' in source:
                for j, subcategory in enumerate(source['subcategories']):
                    if subcategory['id'] == source_id:
                        parent_index = i
                        subcategory_index = j
                        break
        
        if source_index is not None:
            # ë¶€ëª¨ ì¶œì²˜ ì‚­ì œ
            if len(sources) <= 1:
                return jsonify({
                    'success': False,
                    'error': 'ìµœì†Œ í•˜ë‚˜ì˜ ì¶œì²˜ëŠ” ìœ ì§€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.',
                    'code': 'MINIMUM_SOURCES_REQUIRED'
                }), 400
            
            deleted_source = sources.pop(source_index)
        elif parent_index is not None and subcategory_index is not None:
            # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì‚­ì œ
            deleted_source = sources[parent_index]['subcategories'].pop(subcategory_index)
        else:
            return jsonify({
                'success': False,
                'error': 'Source not found',
                'code': 'SOURCE_NOT_FOUND'
            }), 404
        
        # ì €ì¥
        if save_sources(sources):
            logger.info(f"Source deleted: {source_id} - {deleted_source['name']}")
            
            return jsonify({
                'success': True,
                'data': deleted_source,
                'message': 'ì¶œì²˜ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to save sources',
                'code': 'SAVE_ERROR'
            }), 500
            
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to delete source {source_id}: {error_msg}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'success': False,
            'error': f'ì¶œì²˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'DELETE_SOURCE_ERROR'
        }), 500

@app.route('/api/sources/<parent_id>/subcategories', methods=['POST'])
def add_subcategory(parent_id):
    """ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ê°€"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'Request data is required',
                'code': 'MISSING_DATA'
            }), 400
        
        # ë¶€ëª¨ ì¶œì²˜ ì°¾ê¸°
        sources = load_sources()
        parent_source = None
        parent_index = None
        
        for i, source in enumerate(sources):
            if source['id'] == parent_id:
                parent_source = source
                parent_index = i
                break
        
        if not parent_source:
            return jsonify({
                'success': False,
                'error': 'Parent source not found',
                'code': 'PARENT_NOT_FOUND'
            }), 404
        
        if not parent_source.get('is_parent', False):
            return jsonify({
                'success': False,
                'error': 'Source is not a parent source',
                'code': 'NOT_PARENT_SOURCE'
            }), 400
        
        # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ê°ì²´ ìƒì„±
        subcategory_id = data.get('id') or f"sub_{uuid.uuid4().hex[:8]}"
        new_subcategory = {
            'id': subcategory_id,
            'name': data['name'],
            'url': data['url'],
            'parser_type': data.get('parser_type', 'universal'),
            'active': data.get('active', True),
            'description': data.get('description', ''),
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ì´ ì—†ìœ¼ë©´ ìƒì„±
        if 'subcategories' not in parent_source:
            parent_source['subcategories'] = []
        
        # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
        parent_source['subcategories'].append(new_subcategory)
        parent_source['updated_at'] = datetime.now().isoformat()
        
        # ì €ì¥
        if save_sources(sources):
            logger.info(f"Subcategory added: {subcategory_id} - {new_subcategory['name']}")
            
            return jsonify({
                'success': True,
                'data': new_subcategory,
                'message': 'ì„œë¸Œ ì¹´í…Œê³ ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.'
            }), 201
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to save sources',
                'code': 'SAVE_ERROR'
            }), 500
            
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to add subcategory: {error_msg}")
        logger.error(traceback.format_exc())
        
        return jsonify({
            'success': False,
            'error': f'ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}',
            'code': 'ADD_SUBCATEGORY_ERROR'
        }), 500

# ============================================================================
# ê¸°ì¡´ ì—ëŸ¬ í•¸ë“¤ëŸ¬ë“¤
# ============================================================================

@app.errorhandler(413)
def request_entity_too_large(error):
    return jsonify({
        'success': False,
        'error': 'Request entity too large',
        'code': 'REQUEST_TOO_LARGE'
    }), 413

@app.errorhandler(404)
def not_found(error):
    """404 ì—ëŸ¬ ì²˜ë¦¬"""
    # API ìš”ì²­ì¸ ê²½ìš° JSON ì‘ë‹µ
    if request.path.startswith('/api/'):
    return jsonify({
        'success': False,
            'error': 'API endpoint not found',
            'code': 'NOT_FOUND',
            'path': request.path
    }), 404
    
    # favicon ìš”ì²­ì€ ë¹ˆ ì‘ë‹µ
    if request.path.endswith('.ico'):
        return '', 204
    
    # ê¸°íƒ€ ìš”ì²­ì€ ë©”ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
    return send_from_directory('frontend', 'index.html')

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error',
        'code': 'INTERNAL_ERROR'
    }), 500

if __name__ == '__main__':
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('DEBUG', 'False').lower() == 'true'
    
    logger.info(f"ğŸš€ Starting NONGBUXX API server on port {port}")
    logger.info(f"ğŸ”§ Debug mode: {debug}")
    logger.info(f"ğŸŒ Environment: {os.getenv('FLASK_ENV', 'development')}")
    logger.info(f"ğŸ”‘ API Keys - OpenAI: {'SET' if os.getenv('OPENAI_API_KEY') else 'NOT_SET'}, Anthropic: {'SET' if os.getenv('ANTHROPIC_API_KEY') else 'NOT_SET'}")
    
    try:
        app.run(host='0.0.0.0', port=port, debug=debug)
    except Exception as e:
        logger.error(f"âŒ Failed to start server: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise 