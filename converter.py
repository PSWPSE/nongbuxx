import os
from datetime import datetime
from pathlib import Path
import anthropic
from openai import OpenAI
from dotenv import load_dotenv
import re

class NewsConverter:
    def __init__(self, api_provider='anthropic', api_key=None):
        load_dotenv()
        self.api_provider = api_provider.lower()
        self.anthropic_client = None
        self.openai_client = None
        
        # ì‚¬ìš©ì ì œê³µ API í‚¤ë¥¼ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        # ì£¼ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.api_provider == 'anthropic':
            key = api_key if api_key else os.getenv('ANTHROPIC_API_KEY')
            if key:
                self.anthropic_client = anthropic.Anthropic(api_key=key)
                
        elif self.api_provider == 'openai':
            key = api_key if api_key else os.getenv('OPENAI_API_KEY')
            if key:
                self.openai_client = OpenAI(api_key=key)
        
        # í´ë°±ì„ ìœ„í•œ ë³´ì¡° API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì—ì„œë§Œ)
        if self.api_provider == 'anthropic':
            # Anthropicì„ ì‚¬ìš©í•  ë•Œ OpenAI í´ë°±ì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI í‚¤ í™•ì¸
            openai_fallback_key = os.getenv('OPENAI_API_KEY')
            if openai_fallback_key:
                try:
                    self.openai_client = OpenAI(api_key=openai_fallback_key)
                except Exception as e:
                    print(f"[WARN] Failed to initialize OpenAI fallback client: {e}")
        elif self.api_provider == 'openai':
            # OpenAIë¥¼ ì‚¬ìš©í•  ë•Œ Anthropic í´ë°±ì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ì—ì„œ Anthropic í‚¤ í™•ì¸
            anthropic_fallback_key = os.getenv('ANTHROPIC_API_KEY')
            if anthropic_fallback_key:
                try:
                    self.anthropic_client = anthropic.Anthropic(api_key=anthropic_fallback_key)
                except Exception as e:
                    print(f"[WARN] Failed to initialize Anthropic fallback client: {e}")
                    
        self.output_dir = Path('converted_articles')
        self.output_dir.mkdir(exist_ok=True)

    def read_txt_file(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # Parse the content
        title_match = re.search(r'ì œëª©: (.*?)\n={2,}', content)
        meta_match = re.search(r'ë©”íƒ€ ì •ë³´:\ndescription: (.*?)\n-{2,}', content, re.DOTALL)
        content_match = re.search(r'ë³¸ë¬¸:\n(.*?)$', content, re.DOTALL)
        
        title = title_match.group(1) if title_match else ""
        description = meta_match.group(1).strip() if meta_match else ""
        main_content = content_match.group(1).strip() if content_match else ""
        
        return {
            'title': title,
            'description': description,
            'content': main_content
        }

    def clean_response(self, response):
        """Clean the API response text"""
        # Handle different API response formats
        text = str(response)
        text = re.sub(r'\[.*?\]', '', text)
        text = text.replace('TextBlock(citations=None, text=', '')
        text = text.replace(', type=\'text\')', '')
        text = text.strip('"\'')
        text = text.lstrip('\n')
        text = text.replace('\\n', '\n')
        return text.strip()

    def call_api(self, prompt, max_tokens=2000, temperature=0):
        """Call the appropriate API based on provider, fallback to OpenAI if Anthropic fails"""
        # Try Anthropic first if selected
        if self.api_provider == 'anthropic' and self.anthropic_client:
            try:
                message = self.anthropic_client.messages.create(
                    model="claude-3-opus-20240229",
                    max_tokens=max_tokens,
                    temperature=temperature,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                )
                print("[INFO] Used Anthropic API.")
                return message.content[0]
            except Exception as e:
                print(f"[WARN] Anthropic API failed: {e}\nFalling back to OpenAI API...")
                if not self.openai_client:
                    raise RuntimeError("OpenAI API key not set. Cannot fallback.")
                # Fallback to OpenAI
                response = self.openai_client.chat.completions.create(
                    model="gpt-4o",
                    max_tokens=max_tokens,
                    temperature=temperature,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                )
                print("[INFO] Used OpenAI API (fallback).")
                return response.choices[0].message.content
        elif self.api_provider == 'openai' and self.openai_client:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                max_tokens=max_tokens,
                temperature=temperature,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            print("[INFO] Used OpenAI API.")
            return response.choices[0].message.content
        else:
            raise RuntimeError("No valid API client available.")

    def extract_keywords(self, content):
        """Extract keywords from content using selected API"""
        prompt = f"""ê¸°ì‚¬ì—ì„œ 5ê°œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ í•´ì‹œíƒœê·¸ë¡œ ì¶”ì¶œí•˜ì„¸ìš”:

ê·œì¹™:
- í•œê¸€ í•´ì‹œíƒœê·¸ (#í‚¤ì›Œë“œ)
- ê³µë°±ìœ¼ë¡œ êµ¬ë¶„
- ì£¼ì‹ ì¢…ëª© í¬í•¨
- í•´ì‹œíƒœê·¸ë§Œ ë°˜í™˜

Article: {content}"""
        
        response = self.call_api(prompt, max_tokens=300)
        return self.clean_response(response)

    def generate_markdown_content(self, content):
        """Generate markdown content using selected API"""
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ì¸ì§€ í™•ì¸
        is_naver_news = 'news.naver.com' in content.get('url', '') or 'naver' in content.get('source', '').lower()
        
        if is_naver_news:
            # ë„¤ì´ë²„ ë‰´ìŠ¤ëŠ” ì›ë³¸ í•œêµ­ì–´ ì œëª© ê·¸ëŒ€ë¡œ ì‚¬ìš©
            prompt = f"""ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”:

**ğŸš¨ í•„ìˆ˜ ì§€ì‹œì‚¬í•­ - ì ˆëŒ€ ì§€ì¼œì•¼ í•¨:**
- ì œëª©ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë²ˆì—­í•˜ì§€ ë§ ê²ƒ)
- ì œëª© ì•ì— ì ì ˆí•œ ì´ëª¨ì§€ 1ê°œ ì¶”ê°€
- ë„¤ì´ë²„ ë‰´ìŠ¤ëŠ” ì´ë¯¸ í•œêµ­ì–´ì´ë¯€ë¡œ ì œëª© ë²ˆì—­ ê¸ˆì§€

**ğŸ“ ë¬¸ì²´ ê°€ì´ë“œë¼ì¸ (ì¤‘ìš”):**
- **ê°„ê²°í•œ ë‰´ìŠ¤ ìŠ¤íƒ€ì¼**: ëª…í™•í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„
- **ë¬¸ì¥ ì¢…ê²° í˜•íƒœ** (ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©):
  - ë™ì‚¬í˜•: "ê¸°ë¡í•¨", "ë°œí‘œí•¨", "ì¦ê°€í•¨", "ìƒìŠ¹í•¨"
  - ê´€í˜•í˜•: "ì¦ê°€í•œ", "ê¸°ë¡í•œ" (ìˆ˜ì¹˜/ìƒí™© ì„¤ëª… ì‹œ)
  - ëª…ì‚¬í˜•: "í™•ëŒ€", "ê°•í™”", "í˜¸ì¡°", "ë¶€ì§„"
  - ì˜ˆìƒí˜•: "ì˜ˆìƒ", "ì „ë§", "ê¸°ëŒ€", "~í•  ì „ë§"

- **ğŸ”— íë¦„ ì—°ê²° í‘œí˜„** (ë…¼ë¦¬ì  ê´€ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„):
  - **ì¸ê³¼ê´€ê³„**: â†’ (í™”ì‚´í‘œ)ë¡œ ì›ì¸ê³¼ ê²°ê³¼ ì—°ê²°
    ì˜ˆ: "ê¸ˆë¦¬ ì¸ìƒ â†’ ì˜ˆê¸ˆ ìˆ˜ìµë¥  ìƒìŠ¹ â†’ ì€í–‰ ìˆ˜ìµì„± ê°œì„ "
  - **ìˆœì°¨ì  íë¦„**: âœ ë˜ëŠ” â–¶ë¡œ ë‹¨ê³„ë³„ ì§„í–‰ í‘œì‹œ
    ì˜ˆ: "ê°œë°œ ì°©ìˆ˜ âœ ì„ìƒ 1ìƒ âœ FDA ìŠ¹ì¸ ì‹ ì²­"
  - **ëŒ€ë¦½/ì „í™˜**: â†” ë˜ëŠ” vsë¡œ ìƒë°˜ëœ ìƒí™© í‘œí˜„
    ì˜ˆ: "ìˆ˜ì¶œ í˜¸ì¡° â†” ë‚´ìˆ˜ ë¶€ì§„"
  - **ë³‘ë ¬ ê´€ê³„**: â€¢ ë˜ëŠ” ãƒ»ë¡œ ë™ë“±í•œ ìš”ì†Œ ë‚˜ì—´

- **ğŸ“Š ìˆ˜ì¹˜/ë³€í™” í‘œí˜„ ë°©ì‹**:
  - **ìƒìŠ¹**: â†‘ 5% ë˜ëŠ” "ê¸‰ë“±"
  - **í•˜ë½**: â†“ 3% ë˜ëŠ” "ê¸‰ë½"
  - **ë³´í•©**: â†’ 0.1% ë˜ëŠ” "íš¡ë³´"
  - **ì „í™˜ì **: "ë°˜ë“±" ë˜ëŠ” "ìƒìŠ¹ ì „í™˜"

- **ğŸš« ì´ëª¨ì§€ ì‚¬ìš© ê·œì¹™**:
  - âœ… **í—ˆìš©**: ì œëª©ê³¼ ì„¹ì…˜ íƒ€ì´í‹€(â–¶)ì—ë§Œ ì‚¬ìš©
  - âŒ **ê¸ˆì§€**: ë³¸ë¬¸ ë‚´ìš©, í•­ëª© ì„¤ëª…, ì¼ë°˜ ë¬¸ì¥ì—ì„œëŠ” ì‚¬ìš© ê¸ˆì§€
  - **ì˜¬ë°”ë¥¸ ì˜ˆ**:
    â€¢ "ğŸš€ í…ŒìŠ¬ë¼, AI ììœ¨ì£¼í–‰ ê¸°ìˆ  ëŒ€í­ ì—…ê·¸ë ˆì´ë“œ" (ì œëª© - OK)
    â€¢ "â–¶ ì‹¤ì  í•˜ì´ë¼ì´íŠ¸:" (ì„¹ì…˜ - OK)
  - **ì˜ëª»ëœ ì˜ˆ**:
    â€¢ "ë§¤ì¶œì´ ğŸ“ˆ ê¸‰ì¦í•¨" (ë³¸ë¬¸ - ê¸ˆì§€)
    â€¢ "â€¢ ğŸ”¥ ì£¼ê°€ 10% ìƒìŠ¹" (í•­ëª© - ê¸ˆì§€)

- **â±ï¸ ì‹œê°„ íë¦„ í‘œí˜„**:
  - **ê³¼ê±°**: [ê¸°ì¡´] ë˜ëŠ” (ì´ì „)
  - **í˜„ì¬**: [í˜„ì¬] ë˜ëŠ” (ì§€ê¸ˆ)
  - **ë¯¸ë˜**: [í–¥í›„] ë˜ëŠ” (ì˜ˆìƒ)
  - **ì—°ì†ì„±**: ~ ì§€ì† ì¤‘, ~ ì§„í–‰ ì¤‘

- **í”¼í•´ì•¼ í•  í‘œí˜„**: 
  - âŒ ì¡´ëŒ“ë§: "~ìŠµë‹ˆë‹¤", "~í–ˆì–´ìš”", "~í•˜ì„¸ìš”"
  - âŒ ì¥í™©í•œ í‘œí˜„: "~ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤", "~ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤"
  - âŒ ê³¼ë„í•œ ê²½ì–´: "~í•˜ì˜€ë‹¤", "~ë˜ì—ˆë‹¤"

- **ê¶Œì¥ í‘œí˜„ ì˜ˆì‹œ**:
  âœ… "ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€ â†’ ë§¤ì¶œ ìƒìŠ¹ â†’ ì˜ì—…ì´ìµë¥  ê°œì„ "
  âœ… "AI íˆ¬ì í™•ëŒ€ âœ ê¸°ìˆ  ê²½ìŸë ¥ ê°•í™” âœ ì‹œì¥ ì ìœ ìœ¨ ìƒìŠ¹ ê¸°ëŒ€"
  âœ… "ì£¼ê°€: 350ë‹¬ëŸ¬ â†’ 380ë‹¬ëŸ¬ (â†‘8.6%)"
  âœ… "[1ë¶„ê¸°] ì ì â†’ [2ë¶„ê¸°] í‘ì ì „í™˜ â†’ [3ë¶„ê¸°] ìˆ˜ìµì„± ê°œì„  ì „ë§"
  âŒ "TSMCì˜ ìˆœì´ìµì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤"
  âŒ "ìˆ˜ìš”ê°€ ì¦ê°€í•œ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤"

**í˜•ì‹ ê·œì¹™:**
- ì œëª©: ì´ëª¨ì§€ + ì›ë³¸ í•œêµ­ì–´ ì œëª© ê·¸ëŒ€ë¡œ
- ì„¹ì…˜: â–¶ ì„¹ì…˜ëª…: 
- í•­ëª©: â€¢ ë‚´ìš© ë˜ëŠ” 1. ë‚´ìš©

**ì£¼ì‹ ì‹¬ë³¼ ì²˜ë¦¬ ê·œì¹™ (X ì½˜í…ì¸  ì „ìš©):**
- í•œêµ­ ê¸°ì—…: ì¢…ëª©ëª… $í•œêµ­ì½”ë“œ (ì˜ˆ: ì‚¼ì„±ì „ì $005930.KS, SKí•˜ì´ë‹‰ìŠ¤ $000660.KS)
- í•´ì™¸ ê¸°ì—…: ì¢…ëª©ëª… $ë¯¸êµ­ì‹¬ë³¼ (ì˜ˆ: í…ŒìŠ¬ë¼ $TSLA, ì• í”Œ $AAPL)
- ê±°ë˜ì†Œ ì ‘ë¯¸ì‚¬ëŠ” í•œêµ­ ê¸°ì—…(.KS)ë§Œ í—ˆìš©, ê¸°íƒ€ ê±°ë˜ì†Œ ì ‘ë¯¸ì‚¬(.NS, .BO, .L, .TO ë“±) ê¸ˆì§€
- ê´„í˜¸ ì‚¬ìš© ê¸ˆì§€: ì‚¼ì„±ì „ì $005930.KS (ì˜¬ë°”ë¦„), ì‚¼ì„±ì „ì($005930.KS) (ì˜ëª»ë¨)
- **X ì „ìš© ê³µë°± ê·œì¹™**: $ì‹¬ë³¼ ì•ë’¤ë¡œ ë°˜ë“œì‹œ í•œ ì¹¸ì˜ ê³µë°± í™•ë³´ (ì˜ˆ: ì‚¼ì„±ì „ì $005930.KS , í…ŒìŠ¬ë¼ $TSLA ë“±)

ì…ë ¥:
ì œëª©: {content.get('title', '')}
ë‚´ìš©: {content.get('body', '')}

ì¶œë ¥:"""
        else:
            # í•´ì™¸ ë‰´ìŠ¤ëŠ” ê¸°ì¡´ ë²ˆì—­ ë¡œì§ ì ìš©
            prompt = f"""ë‰´ìŠ¤ë¥¼ í•œêµ­ì–´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”:

**ğŸš¨ í•„ìˆ˜ ì§€ì‹œì‚¬í•­ - ì ˆëŒ€ ì§€ì¼œì•¼ í•¨:**
- ì œëª©ì€ 100% í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
- ì˜ì–´ ì œëª©ì´ ì…ë ¥ë˜ì–´ë„ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­
- ì œëª© ì•ì— ì ì ˆí•œ ì´ëª¨ì§€ 1ê°œ ì¶”ê°€

**ğŸ’¡ ë§¤ë ¥ì ì¸ ì œëª© ìƒì„± ê°€ì´ë“œë¼ì¸:**
- ë‹¨ìˆœ ë²ˆì—­ì´ ì•„ë‹Œ ë…ìì˜ ê´€ì‹¬ì„ ë„ëŠ” ë§¤ë ¥ì ì¸ ì œëª© ì‘ì„±
- í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ê³  í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ì„íŒ©íŠ¸ ìˆëŠ” ì œëª©
- "ì™œ?", "ì–´ë–»ê²Œ?", "ë¬´ì—‡ì„?" ë“± ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” ìš”ì†Œ í¬í•¨
- í•µì‹¬ í‚¤ì›Œë“œì™€ ê°ì •ì  ì–´í•„ì„ ê²°í•©í•œ ì œëª©
- ì˜ˆì‹œ: "Why the stock market has shrugged off Trump's latest tariff threats" 
  â†’ "ğŸ”¥ íŠ¸ëŸ¼í”„ ê´€ì„¸ ìœ„í˜‘ì—ë„ ì£¼ì‹ì‹œì¥ì´ ê¿ˆì© ì•ŠëŠ” ë†€ë¼ìš´ ì´ìœ "

**ğŸ“ ë¬¸ì²´ ê°€ì´ë“œë¼ì¸ (ì¤‘ìš”):**
- **ê°„ê²°í•œ ë‰´ìŠ¤ ìŠ¤íƒ€ì¼**: ëª…í™•í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„
- **ë¬¸ì¥ ì¢…ê²° í˜•íƒœ** (ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©):
  - ë™ì‚¬í˜•: "ë°œí‘œí•¨", "ì²´ê²°í•¨", "ìƒìŠ¹í•¨", "í•˜ë½í•¨"
  - ê´€í˜•í˜•: "ë°œí‘œí•œ", "ì²´ê²°í•œ" (ìˆ˜ì¹˜/ìƒí™© ì„¤ëª… ì‹œ)
  - ëª…ì‚¬í˜•: "ìƒìŠ¹", "í•˜ë½", "í™•ëŒ€", "ì¶•ì†Œ"
  - ì˜ˆìƒí˜•: "ì˜ˆì •", "ì „ë§", "ì˜ˆìƒ", "~í•  ê²ƒ"

- **ğŸ”— íë¦„ ì—°ê²° í‘œí˜„** (ë…¼ë¦¬ì  ê´€ê³„ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„):
  - **ì¸ê³¼ê´€ê³„**: â†’ (í™”ì‚´í‘œ)ë¡œ ì›ì¸ê³¼ ê²°ê³¼ ì—°ê²°
    ì˜ˆ: "ì‹ ì œí’ˆ ì¶œì‹œ â†’ ë§¤ì¶œ ì¦ê°€ â†’ ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€"
  - **ìˆœì°¨ì  íë¦„**: âœ ë˜ëŠ” â–¶ë¡œ ë‹¨ê³„ë³„ ì§„í–‰ í‘œì‹œ
    ì˜ˆ: "ê³„ì•½ ì²´ê²° âœ ìƒì‚° ì°©ìˆ˜ âœ í•˜ë°˜ê¸° ì¶œí•˜ ì˜ˆì •"
  - **ëŒ€ë¦½/ì „í™˜**: â†” ë˜ëŠ” vsë¡œ ìƒë°˜ëœ ìƒí™© í‘œí˜„
    ì˜ˆ: "ì˜¨ë¼ì¸ ë§¤ì¶œ ì¦ê°€ â†” ì˜¤í”„ë¼ì¸ ë§¤ì¶œ ê°ì†Œ"
  - **ë³‘ë ¬ ê´€ê³„**: â€¢ ë˜ëŠ” ãƒ»ë¡œ ë™ë“±í•œ ìš”ì†Œ ë‚˜ì—´

- **ğŸ“Š ìˆ˜ì¹˜/ë³€í™” í‘œí˜„ ë°©ì‹**:
  - **ìƒìŠ¹**: â†‘ 10% ë˜ëŠ” "ìƒìŠ¹ì„¸"
  - **í•˜ë½**: â†“ 5% ë˜ëŠ” "í•˜ë½ì„¸"
  - **ë³´í•©**: â†’ ë³€ë™ ì—†ìŒ ë˜ëŠ” "ìœ ì§€"

- **ğŸš« ì´ëª¨ì§€ ì‚¬ìš© ê·œì¹™**:
  - âœ… **í—ˆìš©**: ì œëª©ê³¼ ì„¹ì…˜ íƒ€ì´í‹€(â–¶)ì—ë§Œ ì‚¬ìš©
  - âŒ **ê¸ˆì§€**: ë³¸ë¬¸ ë‚´ìš©, í•­ëª© ì„¤ëª…, ì¼ë°˜ ë¬¸ì¥ì—ì„œëŠ” ì‚¬ìš© ê¸ˆì§€
  - **ì˜¬ë°”ë¥¸ ì˜ˆ**:
    â€¢ "ğŸš¨ ê¸´ê¸‰ì†ë³´: ì‚¼ì„±ì „ì ì‹¤ì  ë°œí‘œ" (ì œëª© - OK)
    â€¢ "â–¶ ì£¼ìš” ë‚´ìš©:" (ì„¹ì…˜ - OK)
  - **ì˜ëª»ëœ ì˜ˆ**:
    â€¢ "ì£¼ê°€ê°€ ğŸš€ ê¸‰ìƒìŠ¹" (ë³¸ë¬¸ - ê¸ˆì§€)
    â€¢ "â€¢ ğŸ’° ë§¤ì¶œ ì¦ê°€" (í•­ëª© - ê¸ˆì§€)
  - **ì „í™˜ì **: ğŸ”„ í„´ì–´ë¼ìš´ë“œ ë˜ëŠ” â¤´ï¸ ë°˜ë“±

- **â±ï¸ ì‹œê°„ íë¦„ í‘œí˜„**:
  - **ê³¼ê±°**: [ì‘ë…„] ë˜ëŠ” (ì¢…ì „)
  - **í˜„ì¬**: [ì˜¬í•´] ë˜ëŠ” (í˜„ì¬)
  - **ë¯¸ë˜**: [ë‚´ë…„] ë˜ëŠ” (ì „ë§)
  - **ì§„í–‰í˜•**: ~ ì¶”ì§„ ì¤‘, ~ ê²€í†  ì¤‘

- **í”¼í•´ì•¼ í•  í‘œí˜„**: 
  - âŒ ì¡´ëŒ“ë§: "~ìŠµë‹ˆë‹¤", "~í–ˆì–´ìš”", "~í•˜ì„¸ìš”"
  - âŒ ì¥í™©í•œ í‘œí˜„: "~ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤", "~ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤"
  - âŒ ê³¼ë„í•œ ê²½ì–´: "~í•˜ì˜€ë‹¤", "~ë˜ì—ˆë‹¤"

- **ê¶Œì¥ í‘œí˜„ ì˜ˆì‹œ**:
  âœ… "ê¸°ìˆ  í˜ì‹  â†’ ìƒì‚°ì„± í–¥ìƒ â†’ ì›ê°€ ì ˆê° íš¨ê³¼"
  âœ… "ê·œì œ ì™„í™” ë°œí‘œ âœ íˆ¬ì ì‹¬ë¦¬ ê°œì„  âœ ì£¼ê°€ ìƒìŠ¹ ê¸°ëŒ€"
  âœ… "ë§¤ì¶œ: 100ì–µì› â†’ 150ì–µì› (â†‘50%)"
  âœ… "[ìƒë°˜ê¸°] íˆ¬ì í™•ëŒ€ â†’ [í•˜ë°˜ê¸°] ì„±ê³¼ ê°€ì‹œí™” ì˜ˆìƒ"
  âŒ "í…ŒìŠ¬ë¼ê°€ ê³µì¥ì„ ê±´ì„¤í–ˆìŠµë‹ˆë‹¤"
  âŒ "ì£¼ê°€ê°€ ìƒìŠ¹í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤"

**ì´ëª¨ì§€ ì„ íƒ ê°€ì´ë“œ:**
- ê¸ˆìœµ/íˆ¬ì: ğŸ’° ğŸ’µ ğŸ“ˆ ğŸ“Š ğŸ”¥
- ê¸°ìˆ /í˜ì‹ : ğŸš€ ğŸ’¡ ğŸ”§ ğŸŒŸ âš¡
- ì •ì±…/ê·œì œ: âš–ï¸ ğŸ“œ ğŸ›ï¸ ğŸ”¨ ğŸš¨
- ê°ˆë“±/ê²½ìŸ: ğŸ”¥ âš”ï¸ ğŸ¯ ğŸ² ğŸ’¥
- í˜‘ë ¥/ê³„ì•½: ğŸ¤ ğŸ“ ğŸŠ ğŸŒˆ âœ¨
- ì„±ì¥/ë°œì „: ğŸŒ± ğŸ‰ ğŸ’ª â­ ğŸ¯

**í˜•ì‹ ê·œì¹™:**
- ì œëª©: ì´ëª¨ì§€ + ë§¤ë ¥ì ì¸ í•œêµ­ì–´ ì œëª© (ì˜ˆ: ğŸ”¥ íŠ¸ëŸ¼í”„ ê´€ì„¸ ìœ„í˜‘ì—ë„ ì£¼ì‹ì‹œì¥ì´ ê¿ˆì© ì•ŠëŠ” ë†€ë¼ìš´ ì´ìœ )
- ì„¹ì…˜: â–¶ ì„¹ì…˜ëª…:
- í•­ëª©: â€¢ ë‚´ìš© ë˜ëŠ” 1. ë‚´ìš©

**ì£¼ì‹ ì‹¬ë³¼ ì²˜ë¦¬ ê·œì¹™ (X ì½˜í…ì¸  ì „ìš©):**
- í•œêµ­ ê¸°ì—…: ì¢…ëª©ëª… $í•œêµ­ì½”ë“œ (ì˜ˆ: ì‚¼ì„±ì „ì $005930.KS, SKí•˜ì´ë‹‰ìŠ¤ $000660.KS)
- í•´ì™¸ ê¸°ì—…: ì¢…ëª©ëª… $ë¯¸êµ­ì‹¬ë³¼ (ì˜ˆ: í…ŒìŠ¬ë¼ $TSLA, ì• í”Œ $AAPL)
- ê±°ë˜ì†Œ ì ‘ë¯¸ì‚¬ëŠ” í•œêµ­ ê¸°ì—…(.KS)ë§Œ í—ˆìš©, ê¸°íƒ€ ê±°ë˜ì†Œ ì ‘ë¯¸ì‚¬(.NS, .BO, .L, .TO ë“±) ê¸ˆì§€
- ê´„í˜¸ ì‚¬ìš© ê¸ˆì§€: í…ŒìŠ¬ë¼ $TSLA (ì˜¬ë°”ë¦„), í…ŒìŠ¬ë¼($TSLA) (ì˜ëª»ë¨)
- **X ì „ìš© ê³µë°± ê·œì¹™**: $ì‹¬ë³¼ ì•ë’¤ë¡œ ë°˜ë“œì‹œ í•œ ì¹¸ì˜ ê³µë°± í™•ë³´ (ì˜ˆ: ì‚¼ì„±ì „ì $005930.KS , í…ŒìŠ¬ë¼ $TSLA ë“±)

ì…ë ¥:
ì œëª©: {content.get('title', '')}
ë‚´ìš©: {content.get('body', '')}

ì¶œë ¥:"""

        response = self.call_api(prompt, max_tokens=800)
        return self.clean_response(response)
    
    def _has_english(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ì— ì˜ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        return bool(re.search(r'[a-zA-Z]', text))
    
    def _has_too_much_english(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ì— ì˜ì–´ê°€ ë„ˆë¬´ ë§ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (50% ì´ìƒ)"""
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        total_chars = len(text.strip())
        return total_chars > 0 and (english_chars / total_chars) > 0.5
    
    def _translate_title_to_korean(self, title: str) -> str:
        """ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­"""
        try:
            prompt = f"""ë‹¤ìŒ ì˜ì–´ ì œëª©ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”. ë‰´ìŠ¤ ì œëª©ìœ¼ë¡œ ì í•©í•˜ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”:

ì˜ì–´ ì œëª©: {title}

í•œêµ­ì–´ ë²ˆì—­:"""
            
            response = self.call_api(prompt, max_tokens=100)
            korean_title = self.clean_response(response).strip()
            
            # ë²ˆì—­ ê²°ê³¼ ê²€ì¦
            if korean_title and len(korean_title) > 3:
                return korean_title
            else:
                return title  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
                
        except Exception as e:
            print(f"[WARN] ì œëª© ë²ˆì—­ ì‹¤íŒ¨: {e}")
            return title  # ì—ëŸ¬ ì‹œ ì›ë³¸ ë°˜í™˜

    def generate_blog_content(self, content):
        """Generate blog-style content using selected API"""
        prompt = f"""ë‰´ìŠ¤ë¥¼ ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

**ğŸš¨ í•„ìˆ˜ ì§€ì‹œì‚¬í•­ - ì ˆëŒ€ ì§€ì¼œì•¼ í•¨:**
- ì œëª©ì€ 100% í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
- ì˜ì–´ ì œëª©ì´ ì…ë ¥ë˜ì–´ë„ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­
- ë„¤ì´ë²„, ì¡°ì„ ì¼ë³´ ë“± í•œêµ­ ë‰´ìŠ¤ëŠ” ì´ë¯¸ í•œêµ­ì–´ì´ë¯€ë¡œ í•œêµ­ì–´ ì œëª© ìœ ì§€
- ì œëª©ë§Œ ì˜ì–´ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš° ì ˆëŒ€ ê¸ˆì§€

**ğŸ’¡ ë§¤ë ¥ì ì¸ ì œëª© ìƒì„± ê°€ì´ë“œë¼ì¸ (í•µì‹¬):**
- ë‹¨ìˆœ ë²ˆì—­ì´ ì•„ë‹Œ ë…ìì˜ ê´€ì‹¬ì„ ë„ëŠ” ë§¤ë ¥ì ì¸ ì œëª© ì‘ì„±
- í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ê³  í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ì„íŒ©íŠ¸ ìˆëŠ” ì œëª©
- "ì™œ?", "ì–´ë–»ê²Œ?", "ë¬´ì—‡ì„?", "ì§„ì§œ?" ë“± ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” ìš”ì†Œ í¬í•¨
- í•µì‹¬ í‚¤ì›Œë“œì™€ ê°ì •ì  ì–´í•„ì„ ê²°í•©í•œ ì œëª©
- ìˆ«ìë‚˜ êµ¬ì²´ì  ë°ì´í„° í™œìš©ìœ¼ë¡œ ì‹ ë¢°ì„± ì¦ëŒ€
- ë…ìì—ê²Œ ì§ì ‘ì  ê´€ì‹¬ì‚¬ë‚˜ ì¶©ê²©ì„ ì£¼ëŠ” í‘œí˜„ ì‚¬ìš©
- ì˜ˆì‹œ ë³€í™˜:
  * "Why the stock market has shrugged off Trump's latest tariff threats" 
    â†’ "íŠ¸ëŸ¼í”„ ê´€ì„¸ í­íƒ„ì—ë„ ì£¼ì‹ì‹œì¥ì´ ë¬´ë¤ë¤í•œ ë†€ë¼ìš´ ì´ìœ "
  * "Apple announces new AI features"
    â†’ "ì• í”Œì´ ê³µê°œí•œ AI ì‹ ê¸°ëŠ¥, ì‚¼ì„±ì—ê²ŒëŠ” ì•…ëª½ì¼ ìˆ˜ë°–ì— ì—†ëŠ” ì´ìœ "

**ë¸”ë¡œê·¸ ì½˜í…ì¸  ì‘ì„± ìš”êµ¬ì‚¬í•­:**
- 4000ì ë‚´ì™¸ì˜ ë¸”ë¡œê·¸ ì½˜í…ì¸ 
- ë…¼ë¦¬ì ì¸ ë¬¸ë‹¨ êµ¬ì„±ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ì¹œê·¼í•˜ê²Œ ì„¤ëª…
- ì¶”ì¶œëœ ë‚´ìš© ì™¸ ì¶”ê°€ ë¦¬ì„œì¹˜ë¥¼ í†µí•œ ë¶„ì„ê³¼ ì „ë§ ì œê³µ
- SEO ìµœì í™” ê³ ë ¤
- ì œëª©, í—¤ë“œë¼ì¸, ì¸ìš©ë¬¸, ê°•ì¡° ë“± ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ í™œìš©
- ë…ìì˜ ê´€ì‹¬ê³¼ ê³µê°ì„ ìœ ë°œí•˜ëŠ” ë‚´ìš© í¬í•¨

**ê¸°ë³¸ ìš”êµ¬ì‚¬í•­:**
- 5000ì ì´ìƒ
- ì¹œê·¼í•œ ë§íˆ¬ ("~ì—ìš”", "~í•´ìš”")
- ## ì†Œì œëª©ìœ¼ë¡œ êµ¬ë¶„ (ë¸”ë¡œê·¸ëŠ” ## ì‚¬ìš© í—ˆìš©)
- **ë§¤ë ¥ì ì¸ í•œêµ­ì–´ ì œëª©** (ì˜ì–´ ì œëª©ì€ í•œêµ­ì–´ë¡œ ë²ˆì—­)
- ì£¼ì‹ ì‹¬ë³¼ í¬í•¨ ($ì‹¬ë³¼, ë¯¸êµ­ ì‹œì¥ ê¸°ì¤€)

**êµ¬ì„±:**
- ë§¤ë ¥ì ì¸ ì œëª©
- í•œì¤„ ìš”ì•½
- ì„œë¡  (ë…ì ê´€ì‹¬ ìœ ë°œ)
- ë³¸ë¬¸ (ë…¼ë¦¬ì  ë¬¸ë‹¨ êµ¬ì„±)
- ì¶”ê°€ ë¶„ì„ ë° ì „ë§
- ê²°ë¡  ë° ë§ˆë¬´ë¦¬
- **í•´ì‹œíƒœê·¸ 5ê°œ (í•„ìˆ˜)**: ê¸€ì˜ ë‚´ìš©ì„ í•µì‹¬ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” í•´ì‹œíƒœê·¸

**êµ¬ì¡°:**
1. ì„íŒ©íŠ¸ ìˆëŠ” **ë§¤ë ¥ì ì¸ í•œêµ­ì–´ ì œëª©**
2. í•œ ì¤„ ìš”ì•½  
3. ì„œë¡  (2-3 ë¬¸ë‹¨)
4. ë³¸ë¬¸ (## ì†Œì œëª©ë³„ êµ¬ë¶„)
5. ê²°ë¡ 

**ğŸ”¥ ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°: ì œëª©ì€ ë¬´ì¡°ê±´ ë§¤ë ¥ì ì¸ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”!**

**ë§ˆë¬´ë¦¬ ìš”êµ¬ì‚¬í•­:**
- ê¸€ì˜ ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ ê¸€ì˜ ë‚´ìš©ì„ í•µì‹¬ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆëŠ” í•´ì‹œíƒœê·¸ë¥¼ ì •í™•íˆ 5ê°œ ì¶”ê°€
- í•´ì‹œíƒœê·¸ í˜•ì‹: #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 #í‚¤ì›Œë“œ3 #í‚¤ì›Œë“œ4 #í‚¤ì›Œë“œ5
- í•´ì‹œíƒœê·¸ëŠ” ê¸€ì˜ í•µì‹¬ ì£¼ì œ, ê´€ë ¨ ê¸°ì—…, ì‚°ì—… ë¶„ì•¼, ì£¼ìš” í‚¤ì›Œë“œ ë“±ì„ í¬í•¨
- í•´ì‹œíƒœê·¸ ì•ì— "**íƒœê·¸:**"ë¼ëŠ” ì œëª©ì„ ë¶™ì„

ì…ë ¥:
ì œëª©: {content['title']}
ì„¤ëª…: {content['description']}
ë³¸ë¬¸: {content['content']}

ë…ìê°€ ëê¹Œì§€ í¥ë¯¸ë¡­ê²Œ ì½ì„ ìˆ˜ ìˆëŠ” 5000ì ì´ìƒ í•œêµ­ì–´ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”. ì œëª©ì€ ë°˜ë“œì‹œ ë§¤ë ¥ì ì¸ í•œêµ­ì–´ë¡œ!"""
        
        response = self.call_api(prompt, max_tokens=4000)
        return self.clean_response(response)

    def generate_threads_content(self, content):
        """Generate Threads-style content using selected API (490ì ë¯¸ë§Œ)"""
        prompt = f"""ë‰´ìŠ¤ë¥¼ Threadsìš© ì§§ì€ ì½˜í…ì¸ ë¡œ ì‘ì„±í•˜ì„¸ìš”:

**ğŸš¨ í•„ìˆ˜ ì§€ì‹œì‚¬í•­ - ì ˆëŒ€ ì§€ì¼œì•¼ í•¨:**
- ì œëª©ì€ 100% í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
- ì˜ì–´ ì œëª©ì´ ì…ë ¥ë˜ì–´ë„ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­
- ë„¤ì´ë²„, ì¡°ì„ ì¼ë³´ ë“± í•œêµ­ ë‰´ìŠ¤ëŠ” ì´ë¯¸ í•œêµ­ì–´ì´ë¯€ë¡œ í•œêµ­ì–´ ì œëª© ìœ ì§€

**ğŸ’¡ ë§¤ë ¥ì ì¸ ì œëª© ìƒì„± ê°€ì´ë“œë¼ì¸:**
- ë‹¨ìˆœ ë²ˆì—­ì´ ì•„ë‹Œ ë…ìì˜ ê´€ì‹¬ì„ ë„ëŠ” ë§¤ë ¥ì ì¸ ì œëª© ì‘ì„±
- í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ê³  í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ì„íŒ©íŠ¸ ìˆëŠ” ì œëª©
- "ì™œ?", "ì–´ë–»ê²Œ?", "ì§„ì§œ?" ë“± ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” ìš”ì†Œ í¬í•¨
- ì˜ˆì‹œ: "Why the stock market..." â†’ "ğŸ”¥ íŠ¸ëŸ¼í”„ ê´€ì„¸ ìœ„í˜‘ì—ë„ ì£¼ì‹ì‹œì¥ì´ ê¿ˆì© ì•ŠëŠ” ì´ìœ "

**ğŸ“± Threads ì „ìš© ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ë§ í†¤ì•¤ë§¤ë„ˆ:**
- **ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ë§ ì‚¬ìš©**: ì¡´ëŒ“ë§ ì‚¬ìš©í•˜ì§€ ì•Šë˜, ì–µì§€ìŠ¤ëŸ½ì§€ ì•Šê²Œ
- **ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•˜ëŠ” í†¤**: ì¹œê·¼í•˜ë©´ì„œë„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ëŠë‚Œ
- **ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ë§ íŒ¨í„´**:
  * "~ë‹¤" / "~ì§€" / "~í•´" / "~ë„¤" / "~ê±°ì•¼" / "~ëŠ” ê±°ì•¼"
  * "ì´ê²Œ ì¤‘ìš”í•œ í¬ì¸íŠ¸ì•¼" / "ìƒí™©ì´ ì´ë ‡ë‹¤" / "ê²°ê³¼ì ìœ¼ë¡œëŠ” ì´ëŸ° ê±°ì§€"
  * "ë³´ë©´" / "ê·¸ëŸ°ë°" / "ê·¼ë°" / "ê·¸ë˜ì„œ" / "ê²°êµ­ì€"
- **ì˜¤ë²„í•˜ì§€ ì•ŠëŠ” í‘œí˜„**: "ëŒ€ë°•", "ì™„ì „", "í—" ë“± ê³¼í•œ í‘œí˜„ ìì œ
- **ì„¤ëª…í•˜ëŠ” ëŠë‚Œ**: ë‰´ìŠ¤ë¥¼ ì°¨ê·¼ì°¨ê·¼ ì •ë¦¬í•´ì„œ ì•Œë ¤ì£¼ëŠ” í†¤
- **ê°„ê²°í•˜ë©´ì„œë„ ëª…í™•í•œ ë¬¸ì¥**: í•„ìš”í•œ ë‚´ìš©ì€ ë†“ì¹˜ì§€ ì•Šë˜ ê°„ê²°í•˜ê²Œ

**ğŸ’¬ ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª…ì²´ ê°€ì´ë“œë¼ì¸:**
- **ë…¼ë¦¬ì  ìˆœì„œë¡œ ì„¤ëª…**: ìƒí™© â†’ ì›ì¸ â†’ ê²°ê³¼ ìˆœìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ
- **ì ì ˆí•œ ì—°ê²°ì–´ ì‚¬ìš©**: "ê·¸ëŸ°ë°", "ê·¼ë°", "ê·¸ë˜ì„œ", "ê²°êµ­", "ë³´ë©´" ë“±
- **ê°•ì¡°í•  ë•ŒëŠ” ì°¨ë¶„í•˜ê²Œ**: "ì´ê²Œ í•µì‹¬ì´ë‹¤", "ì¤‘ìš”í•œ ê±´", "ì£¼ëª©í•  ì ì€" ë“±
- **ì§ˆë¬¸ í˜•íƒœ ìì œ**: "ì•Œê² ì§€?", "ì–´ë•Œ?" ê°™ì€ í‘œí˜„ ìµœì†Œí™”

**ğŸ”¥ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ë§ ì˜ˆì‹œ:**
- âŒ "ì´ê±° ì§„ì§œ ì¤‘ìš”í•´!" â†’ âœ… "ì´ê²Œ ì¤‘ìš”í•œ í¬ì¸íŠ¸ë‹¤"
- âŒ "ì£¼ê°€ ì™„ì „ ì˜¬ëì–´!" â†’ âœ… "ì£¼ê°€ê°€ ë§ì´ ì˜¬ëë„¤"  
- âŒ "ì™„ì „ ì˜í–¥ ì¤„ ê²ƒ ê°™ì•„!" â†’ âœ… "ì˜í–¥ì„ ì¤„ ê²ƒ ê°™ë‹¤"
- âŒ "ì´ê±° ê¼­ ë´ì•¼ í•´!" â†’ âœ… "ì£¼ëª©í•´ë³¼ ë§Œí•˜ë‹¤"

**ğŸ’¬ ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª… ì˜ˆì‹œ:**
- âŒ "ì´ íšŒì‚¬ê°€ ë­ í•˜ëŠ” ê³³ì´ëƒë©´. ì „ê¸°ì°¨ ë°°í„°ë¦¬ ë§Œë“œëŠ” íšŒì‚¬ì•¼. ê·¼ë° ì´ë²ˆì— 500ë§Œ ë‹¬ëŸ¬ì§œë¦¬ ê³„ì•½ ë”°ëƒˆì–´"
- âœ… "ì´ íšŒì‚¬ëŠ” ì „ê¸°ì°¨ ë°°í„°ë¦¬ ì†Œì¬ë¥¼ ë§Œë“œëŠ” ê³³ì´ë‹¤. ì´ë²ˆì— 500ë§Œ ë‹¬ëŸ¬ ê·œëª¨ì˜ ê³„ì•½ì„ ì²´ê²°í–ˆë„¤"

**ì´ëª¨ì§€ ì„ íƒ ê°€ì´ë“œ:**
- ê¸ˆìœµ/íˆ¬ì: ğŸ’° ğŸ’µ ğŸ“ˆ ğŸ“Š ğŸ”¥
- ê¸°ìˆ /í˜ì‹ : ğŸš€ ğŸ’¡ ğŸ”§ ğŸŒŸ âš¡
- ì •ì±…/ê·œì œ: âš–ï¸ ğŸ“œ ğŸ›ï¸ ğŸ”¨ ğŸš¨
- ê°ˆë“±/ê²½ìŸ: ğŸ”¥ âš”ï¸ ğŸ¯ ğŸ² ğŸ’¥
- í˜‘ë ¥/ê³„ì•½: ğŸ¤ ğŸ“ ğŸŠ ğŸŒˆ âœ¨

**ì œì•½ì‚¬í•­:**
- 490ì ë¯¸ë§Œ (í•„ìˆ˜)
- ì´ëª¨ì§€ + ë§¤ë ¥ì ì¸ í•œêµ­ì–´ ì œëª© (ì˜ˆ: ğŸ”¥ íŠ¸ëŸ¼í”„ ê´€ì„¸ ìœ„í˜‘ì—ë„ ì£¼ì‹ì‹œì¥ì´ ê¿ˆì© ì•ŠëŠ” ì´ìœ )
- â–¶ ì„¹ì…˜: (ì™„ì „ ë°˜ë§ë¡œ ì„¹ì…˜ëª… ì‘ì„± - "ë¬´ìŠ¨ ì¼ì´ì•¼?", "ì™œ ì¤‘ìš”í•´?", "ì–´ë–»ê²Œ ë ê¹Œ?" ë“±)
- â€¢ ì£¼ìš” ë‚´ìš© (ëª¨ë“  ì„¤ëª…ì„ ì§§ì€ ë°˜ë§ ëŒ€í™”ì²´ë¡œ ì‘ì„±)
- ê¸€ììˆ˜ ì •ë³´ë‚˜ ë©”íƒ€ ì •ë³´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•Šê¸°

**ì£¼ì‹ ì‹¬ë³¼ ì²˜ë¦¬ ê·œì¹™:**
- í•œêµ­ ê¸°ì—…: ì¢…ëª©ëª… $í•œêµ­ì½”ë“œ (ì˜ˆ: ì‚¼ì„±ì „ì $005930.KS, SKí•˜ì´ë‹‰ìŠ¤ $000660.KS)
- í•´ì™¸ ê¸°ì—…: ì¢…ëª©ëª… $ë¯¸êµ­ì‹¬ë³¼ (ì˜ˆ: í…ŒìŠ¬ë¼ $TSLA, ì• í”Œ $AAPL)
- ê±°ë˜ì†Œ ì ‘ë¯¸ì‚¬ëŠ” í•œêµ­ ê¸°ì—…(.KS)ë§Œ í—ˆìš©, ê¸°íƒ€ ê±°ë˜ì†Œ ì ‘ë¯¸ì‚¬(.NS, .BO, .L, .TO ë“±) ê¸ˆì§€
- ê´„í˜¸ ì‚¬ìš© ê¸ˆì§€: ì‚¼ì„±ì „ì $005930.KS (ì˜¬ë°”ë¦„), ì‚¼ì„±ì „ì($005930.KS) (ì˜ëª»ë¨)

**ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ë§ í˜•ì‹ ì˜ˆì‹œ:**
ğŸ”¥ [ë§¤ë ¥ì ì¸ í•œêµ­ì–´ ì œëª©]

â–¶ ìƒí™© ì •ë¦¬:
â€¢ ì´ íšŒì‚¬ê°€ í° ê³„ì•½ì„ ì²´ê²°í–ˆë‹¤
â€¢ ì‹œì¥ì—ì„œ ì£¼ëª©ë°›ê³  ìˆëŠ” ìƒí™©ì´ë„¤

â–¶ í•µì‹¬ í¬ì¸íŠ¸:
â€¢ ì´ê²Œ ì¤‘ìš”í•œ ì´ìœ ëŠ” ì´ê±°ë‹¤
â€¢ ì•ìœ¼ë¡œ ì´ëŸ° ì˜í–¥ì„ ì¤„ ê²ƒ ê°™ë‹¤

**ğŸ”¥ í•µì‹¬: ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ë§ë¡œ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•˜ë˜, ì˜¤ë²„í•˜ì§€ ì•Šê²Œ!**

ì…ë ¥:
ì œëª©: {content['title']}
ì„¤ëª…: {content['description']}
ë³¸ë¬¸: {content['content']}

490ì ë¯¸ë§Œìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ë§ë¡œ ì°¨ê·¼ì°¨ê·¼ ì •ë¦¬í•´ì„œ ì‘ì„±í•´. ì˜¤ë²„í•˜ì§€ ì•Šë˜ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ!"""
        
        response = self.call_api(prompt, max_tokens=800)
        cleaned_response = self.clean_response(response)
        
        # ê¸€ììˆ˜ ì²´í¬ ë° í•„ìš”ì‹œ ìë™ ë‹¨ì¶• (ê¸€ììˆ˜ ì •ë³´ëŠ” ì½˜í…ì¸ ì— í¬í•¨í•˜ì§€ ì•ŠìŒ)
        char_count = len(cleaned_response)
        if char_count >= 490:
            lines = cleaned_response.split('\n')
            shortened_content = []
            current_length = 0
            
            for line in lines:
                if current_length + len(line) + 1 < 490:
                    shortened_content.append(line)
                    current_length += len(line) + 1
                else:
                    if shortened_content:
                        shortened_content.append("...")
                    break
            
            cleaned_response = '\n'.join(shortened_content)
        
        return cleaned_response

    def generate_x_content(self, content):
        """Generate X(Twitter)-style content using selected API (280ì ë‚´ì™¸)"""
        prompt = f"""ë‰´ìŠ¤ë¥¼ X(Twitter)ìš© ê°„ê²°í•œ ì½˜í…ì¸ ë¡œ ì‘ì„±í•˜ì„¸ìš”:

**ğŸš¨ í•„ìˆ˜ ì§€ì‹œì‚¬í•­ - ì ˆëŒ€ ì§€ì¼œì•¼ í•¨:**
- ì œëª©ì€ 100% í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
- ì˜ì–´ ì œëª©ì´ ì…ë ¥ë˜ì–´ë„ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë²ˆì—­
- ë„¤ì´ë²„, ì¡°ì„ ì¼ë³´ ë“± í•œêµ­ ë‰´ìŠ¤ëŠ” ì´ë¯¸ í•œêµ­ì–´ì´ë¯€ë¡œ í•œêµ­ì–´ ì œëª© ìœ ì§€

**ğŸ’¡ X(Twitter) ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸:**
- **280ì ë‚´ì™¸**: ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸ ìˆê²Œ
- **ë‰´ìŠ¤ í•˜ì´ë¼ì´íŠ¸**: ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë§Œ ì••ì¶•
- **í•´ì‹œíƒœê·¸**: 2-3ê°œì˜ ê´€ë ¨ í•´ì‹œíƒœê·¸ í¬í•¨
- **ë¦¬íŠ¸ìœ— ìœ ë„**: ê³µìœ í•˜ê³  ì‹¶ì€ ì¸ì‚¬ì´íŠ¸ í¬í•¨

**âœï¸ X(Twitter) íŠ¹í™” ì‘ì„±ë²•:**
- **í›„í‚¹ ë¬¸ì¥**: ì²« ë¬¸ì¥ì—ì„œ ë…ì ê´€ì‹¬ í™•ë³´
- **ìˆ«ì/ë°ì´í„°**: êµ¬ì²´ì  ìˆ˜ì¹˜ë¡œ ì‹ ë¢°ì„± ì œê³ 
- **ì˜ê²¬ í¬í•¨**: íŒ©íŠ¸ì™€ í•¨ê»˜ ê°„ë‹¨í•œ í•´ì„ ì¶”ê°€
- **ëŒ€í™” ìœ ë„**: ì§ˆë¬¸ì´ë‚˜ ì˜ê²¬ ìš”ì²­ìœ¼ë¡œ ë§ˆë¬´ë¦¬

**ğŸ”¸ X ì½˜í…ì¸  ì „ìš© ë³¸ë¬¸ í˜•ì‹ (ì¤‘ìš”):**
- **ê° ë¬¸ì¥ì„ ë¶ˆë › í¬ì¸íŠ¸(â€¢)ë¡œ ì‹œì‘**
- **ë¬¸ì¥ ë§ˆë¬´ë¦¬ë§ˆë‹¤ ì¤„ë°”ê¿ˆ ì²˜ë¦¬**
- **ê°„ê²°í•œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì •ë³´ ì „ë‹¬**

**ì´ëª¨ì§€ í™œìš©:**
- í•µì‹¬ ë‚´ìš© ê°•ì¡°ìš© ì´ëª¨ì§€ 1-2ê°œ
- ê³¼ë„í•œ ì‚¬ìš© ìì œ
- ì „ë¬¸ì„± ìœ ì§€í•˜ë©´ì„œ ê°€ë…ì„± í–¥ìƒ

**í˜•ì‹ ì˜ˆì‹œ:**
ğŸš¨ [í•µì‹¬ ë‰´ìŠ¤ ì œëª©]

â€¢ [ì²« ë²ˆì§¸ í•µì‹¬ ì •ë³´ ë¬¸ì¥]
â€¢ [ë‘ ë²ˆì§¸ í•µì‹¬ ì •ë³´ ë¬¸ì¥]
â€¢ [ì„¸ ë²ˆì§¸ í•µì‹¬ ì •ë³´ ë¬¸ì¥]
â€¢ [ì¸ì‚¬ì´íŠ¸ ë˜ëŠ” ì˜í–¥]

#í•´ì‹œíƒœê·¸1 #í•´ì‹œíƒœê·¸2 #í•´ì‹œíƒœê·¸3

**ì£¼ì‹ ì‹¬ë³¼ ê·œì¹™:**
- í•œêµ­: ì¢…ëª©ëª… $í•œêµ­ì½”ë“œ (ì˜ˆ: ì‚¼ì„±ì „ì $005930.KS)
- í•´ì™¸: ì¢…ëª©ëª… $ë¯¸êµ­ì‹¬ë³¼ (ì˜ˆ: í…ŒìŠ¬ë¼ $TSLA)
- ê±°ë˜ì†Œ ì ‘ë¯¸ì‚¬ëŠ” í•œêµ­(.KS)ë§Œ í—ˆìš©

ì…ë ¥:
ì œëª©: {content['title']}
ë³¸ë¬¸: {content['body']}

280ì ë‚´ì™¸ë¡œ í•µì‹¬ì„ ì••ì¶•í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”. ê° ë¬¸ì¥ì€ ë¶ˆë › í¬ì¸íŠ¸(â€¢)ë¡œ ì‹œì‘í•˜ê³  ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”."""
        
        response = self.call_api(prompt, max_tokens=500)
        cleaned_response = self.clean_response(response)
        
        # 280ì ì²´í¬ ë° í•„ìš”ì‹œ ìë™ ì¡°ì •
        char_count = len(cleaned_response)
        if char_count > 320:  # ì—¬ìœ ë¥¼ ë‘ê³  320ìë¡œ ì„¤ì •
            # í•´ì‹œíƒœê·¸ëŠ” ë³´ì¡´í•˜ë©´ì„œ ë³¸ë¬¸ ì¶•ì•½
            parts = cleaned_response.split('\n')
            hashtag_line = None
            main_content = []
            
            for i, part in enumerate(parts):
                if '#' in part and part.count('#') >= 2:
                    hashtag_line = part
                    main_content = parts[:i]
                    break
            
            if hashtag_line:
                # ë³¸ë¬¸ë§Œ ì¶•ì•½
                shortened_main = '\n'.join(main_content)[:250] + '...'
                cleaned_response = shortened_main + '\n\n' + hashtag_line
            else:
                cleaned_response = cleaned_response[:280] + '...'
        
        return cleaned_response

    def convert_from_data(self, extracted_data):
        """
        ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ì§ì ‘ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (ìµœì í™”ëœ ë©”ì„œë“œ)
        
        Args:
            extracted_data: WebExtractorì—ì„œ ì¶”ì¶œëœ ë°ì´í„° êµ¬ì¡°
            
        Returns:
            str: ë³€í™˜ëœ ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ 
        """
        # ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ë³€í™˜ê¸°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
        content_text = extracted_data['content']['text']
        
        # ì œëª©ê³¼ ì„¤ëª… ì¶”ì¶œ
        title = extracted_data['title']
        description = extracted_data.get('description', '')
        
        # ë³€í™˜ìš© ë°ì´í„° êµ¬ì¡° ìƒì„±
        data = {
            'title': title,
            'description': description,
            'content': content_text
        }
        
        # ë§ˆí¬ë‹¤ìš´ ìƒì„±
        markdown_content = self.generate_markdown_content(data)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.extract_keywords(f"{title}\n{description}\n{content_text}")
        
        # ìµœì¢… ì½˜í…ì¸  (ë§ˆí¬ë‹¤ìš´ + í‚¤ì›Œë“œ)
        final_content = f"{markdown_content}\n\n{keywords}"
        
        return final_content

    def convert_from_data_blog(self, extracted_data):
        """
        ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ë¸”ë¡œê·¸ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
        
        Args:
            extracted_data: WebExtractorì—ì„œ ì¶”ì¶œëœ ë°ì´í„° êµ¬ì¡°
            
        Returns:
            str: ë³€í™˜ëœ ë¸”ë¡œê·¸ ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ 
        """
        # ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ë³€í™˜ê¸°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
        content_text = extracted_data['content']['text']
        
        # ì œëª©ê³¼ ì„¤ëª… ì¶”ì¶œ
        title = extracted_data['title']
        description = extracted_data.get('description', '')
        
        # ë³€í™˜ìš© ë°ì´í„° êµ¬ì¡° ìƒì„±
        data = {
            'title': title,
            'description': description,
            'content': content_text
        }
        
        # ë¸”ë¡œê·¸ ë§ˆí¬ë‹¤ìš´ ìƒì„±
        blog_content = self.generate_blog_content(data)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.extract_keywords(f"{title}\n{description}\n{content_text}")
        
        # ìµœì¢… ì½˜í…ì¸  (ë¸”ë¡œê·¸ ë§ˆí¬ë‹¤ìš´ + í‚¤ì›Œë“œ)
        final_content = f"{blog_content}\n\n---\n\n**í‚¤ì›Œë“œ:** {keywords}"
        
        return final_content

    def convert_to_markdown(self, data):
        """Convert parsed data to markdown format"""
        # Generate markdown content
        markdown_content = self.generate_markdown_content(data)
        
        # Extract keywords
        keywords = self.extract_keywords(f"{data['title']}\n{data['description']}\n{data['content']}")
        
        # Combine content and keywords with proper spacing
        final_content = f"{markdown_content}\n\n{keywords}"
        
        return final_content

    def process_file(self, file_path):
        """Process a single TXT file"""
        print(f"Processing {file_path} with {self.api_provider} API...")
        data = self.read_txt_file(file_path)
        markdown_content = self.convert_to_markdown(data)
        
        # Create output filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"{Path(file_path).stem}_{timestamp}.md"
        output_path = self.output_dir / output_filename
        
        # Save markdown content
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"Created {output_path}")

    def process_directory(self, directory_path):
        """Process all TXT files in a directory"""
        directory = Path(directory_path)
        for txt_file in directory.glob('*.txt'):
            self.process_file(txt_file)

def main():
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python converter.py <txt_file_or_directory> [api_provider]")
        print("api_provider options: anthropic (default) or openai")
        print("\nExamples:")
        print("  python converter.py article.txt")
        print("  python converter.py article.txt openai")
        print("  python converter.py ./articles/")
        print("  python converter.py ./articles/ openai")
        sys.exit(1)
    
    path = sys.argv[1]
    api_provider = sys.argv[2] if len(sys.argv) > 2 else 'anthropic'
    
    # Validate API provider
    if api_provider not in ['anthropic', 'openai']:
        print("Error: api_provider must be 'anthropic' or 'openai'")
        sys.exit(1)
    
    # Check if required API key is set
    if api_provider == 'anthropic' and not os.getenv('ANTHROPIC_API_KEY'):
        print("Error: ANTHROPIC_API_KEY environment variable is required")
        print("Please set your Anthropic API key in the .env file")
        sys.exit(1)
    elif api_provider == 'openai' and not os.getenv('OPENAI_API_KEY'):
        print("Error: OPENAI_API_KEY environment variable is required")
        print("Please set your OpenAI API key in the .env file")
        sys.exit(1)
    
    converter = NewsConverter(api_provider=api_provider)
    
    if os.path.isfile(path):
        converter.process_file(path)
    elif os.path.isdir(path):
        converter.process_directory(path)
    else:
        print(f"Error: {path} is not a valid file or directory")
        sys.exit(1)

if __name__ == '__main__':
    main() 