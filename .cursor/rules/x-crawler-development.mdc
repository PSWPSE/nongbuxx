---
description: X 크롤링&요약게시 기능 개발 가이드라인
---

# X 크롤링&요약게시 기능 개발 가이드

## 📋 프로젝트 개요
X(Twitter) 인플루언서의 포스트를 자동으로 수집하고, AI로 요약한 후 정해진 시간에 자동으로 게시하는 독립적인 기능 모듈 개발

## 🎯 핵심 요구사항
1. **완전 독립 모듈**: 기존 뉴스 추출 기능과 완전히 분리된 독립 화면
2. **자동화 중심**: 정해진 시간에 수집/게시하는 스케줄링 기능이 핵심
3. **X API 통합**: 기존 X API 설정을 크롤러 전용 화면으로 이전
4. **무영향 원칙**: 기존 기능에 영향 없이 개발

## 🏗️ 아키텍처 구조

### 파일 구조
```
nongbuxx/
├── frontend/
│   ├── index.html (메인 - X 크롤링 버튼 추가)
│   ├── x-crawler.html (신규 - 독립 화면)
│   ├── script.js (기존 유지)
│   ├── x-crawler.js (신규 - 크롤러 전용)
│   └── x-crawler.css (신규 - 크롤러 전용 스타일)
├── x_crawler.py (신규 - 백엔드 크롤링 서비스)
├── scheduler_service.py (신규 - 스케줄링 서비스)
└── app.py (기존 - 크롤러 라우트 추가)
```

## 🔧 개발 순서

### Phase 1: 기본 인프라 (Day 1-2)
1. **메인 화면 진입점 추가**
   - [index.html](mdc:frontend/index.html)에 "X 크롤링&요약게시" 버튼 추가
   - 버튼 클릭 시 x-crawler.html로 이동

2. **독립 화면 생성**
   - frontend/x-crawler.html 생성
   - 완전히 독립된 HTML 구조
   - 자체 네비게이션 (메인으로 돌아가기 버튼)

3. **X API 설정 마이그레이션**
   - 기존 X API 설정 UI를 x-crawler.html로 이동
   - 읽기/쓰기 권한 분리 UI 구현
   - localStorage 키 호환성 유지 ('x_credentials')

### Phase 2: 스케줄링 시스템 (Day 3-4)
1. **백엔드 스케줄러 구현**
   ```python
   # scheduler_service.py
   from apscheduler.schedulers.background import BackgroundScheduler
   
   class XCrawlerScheduler:
       def __init__(self):
           self.scheduler = BackgroundScheduler()
       
       def add_collection_job(self, time, influencers):
           # 수집 작업 스케줄링
       
       def add_publish_job(self, time, content):
           # 게시 작업 스케줄링
   ```

2. **프론트엔드 스케줄 관리**
   ```javascript
   // x-crawler.js
   class ScheduleManager {
       setCollectionTimes(times) { }
       setPublishTimes(times) { }
       getScheduleStatus() { }
   }
   ```

### Phase 3: 자동화 워커 (Day 5-6)
1. **자동 수집 워커**
   - 인플루언서별 최신 포스트 수집
   - AI 요약 자동 생성
   - 게시 큐에 추가

2. **자동 게시 워커**
   - 게시 큐 모니터링
   - 정해진 시간에 X 게시
   - 결과 로깅

### Phase 4: 모니터링 & 통계 (Day 7)
1. **실시간 상태 모니터링**
2. **실행 히스토리 기록**
3. **통계 대시보드**

## 💻 API 엔드포인트

### 크롤러 전용 API
```python
# app.py에 추가할 라우트
@app.route('/api/x-crawler/schedule', methods=['GET', 'POST'])
@app.route('/api/x-crawler/influencers', methods=['GET', 'POST', 'DELETE'])
@app.route('/api/x-crawler/collect', methods=['POST'])
@app.route('/api/x-crawler/summarize', methods=['POST'])
@app.route('/api/x-crawler/publish', methods=['POST'])
@app.route('/api/x-crawler/queue', methods=['GET'])
@app.route('/api/x-crawler/history', methods=['GET'])
@app.route('/api/x-crawler/stats', methods=['GET'])
```

## 🎨 UI/UX 가이드라인

### 디자인 원칙
1. **독립성**: 메인 화면과 완전히 다른 레이아웃
2. **자동화 중심**: 스케줄과 상태가 한눈에 보이는 대시보드
3. **직관성**: 복잡한 기능을 단순한 UI로 표현

### 색상 스키마
```css
/* x-crawler.css */
:root {
    --x-primary: #1DA1F2;    /* X 브랜드 컬러 */
    --x-secondary: #14171A;   /* 다크 그레이 */
    --x-accent: #657786;      /* 라이트 그레이 */
    --x-success: #17BF63;     /* 성공 */
    --x-warning: #FFAD1F;     /* 경고 */
    --x-error: #E0245E;       /* 에러 */
}
```

## 🔒 보안 고려사항

1. **API 키 관리**
   - 모든 X API 키는 localStorage에 암호화 저장
   - 서버로는 인증 확인 시에만 전송
   - 읽기/쓰기 권한 분리 관리

2. **Rate Limiting**
   - X API 제한 준수 (읽기: 15분당 15-75 요청)
   - 백오프 전략 구현
   - 요청 큐잉 시스템

## ⚠️ 주의사항

### 기존 기능 보호
1. **격리 원칙**
   - 새 JavaScript는 x-crawler.js에만 작성
   - 기존 script.js 수정 최소화
   - 전역 변수 충돌 방지 (네임스페이스 사용)

2. **localStorage 키 관리**
   ```javascript
   // 기존 키 (변경 금지)
   'x_credentials'     // X API 인증 정보
   'api_settings'      // OpenAI/Anthropic API
   'user_preferences'  // 사용자 설정
   
   // 신규 키 (크롤러 전용)
   'x_crawler_schedule'     // 스케줄 설정
   'x_crawler_influencers'  // 인플루언서 목록
   'x_crawler_queue'        // 게시 큐
   ```

3. **라우팅 충돌 방지**
   - 모든 크롤러 API는 `/api/x-crawler/` 프리픽스 사용
   - 기존 라우트와 충돌 없음 확인

## 📊 데이터 모델

### 스케줄 설정
```javascript
const scheduleConfig = {
    collection: {
        enabled: true,
        times: ['09:00', '15:00', '21:00'],
        influencers: ['@elonmusk', '@sundarpichai']
    },
    publishing: {
        enabled: true,
        mode: 'auto', // 'auto' | 'manual'
        delay: 60, // 분
        times: ['10:00', '16:00', '22:00']
    }
};
```

### 게시 큐
```javascript
const publishQueue = [
    {
        id: 'q_001',
        content: '요약된 콘텐츠',
        scheduledFor: '2024-08-28T10:00:00',
        status: 'pending', // 'pending' | 'published' | 'failed'
        retryCount: 0
    }
];
```

## 🚀 배포 체크리스트

### 배포 전 확인
- [ ] 기존 뉴스 추출 기능 정상 작동
- [ ] X API 설정 마이그레이션 완료
- [ ] 스케줄러 백그라운드 작업 테스트
- [ ] 자동 수집/게시 시뮬레이션
- [ ] 에러 핸들링 및 재시도 로직
- [ ] 로그 및 모니터링 설정

### 단계별 배포
1. **Stage 1**: UI만 배포 (기능 비활성화)
2. **Stage 2**: 수동 수집/게시 기능 활성화
3. **Stage 3**: 자동화 기능 활성화
4. **Stage 4**: 전체 기능 오픈

## 📝 테스트 시나리오

### 기능 테스트
1. X API 인증 (읽기/쓰기 분리)
2. 인플루언서 추가/삭제
3. 수동 포스트 수집
4. AI 요약 생성
5. 수동 X 게시
6. 스케줄 설정
7. 자동 수집 실행
8. 자동 게시 실행
9. 실패 시 재시도
10. 통계 및 히스토리

### 통합 테스트
1. 기존 뉴스 추출과 동시 사용
2. 서버 재시작 시 스케줄 복구
3. 대량 데이터 처리
4. API Rate Limit 도달 시나리오

## 🔄 유지보수 가이드

### 로그 관리
```python
# 크롤러 전용 로그
logging.getLogger('x_crawler').setLevel(logging.INFO)
logging.getLogger('scheduler').setLevel(logging.INFO)
```

### 백업 전략
- 스케줄 설정: 일일 백업
- 게시 큐: 실시간 백업
- 실행 히스토리: 주간 아카이빙

## 📚 참고 자료

- [X API v2 문서](https://developer.twitter.com/en/docs/twitter-api)
- [APScheduler 문서](https://apscheduler.readthedocs.io/)
- [Tweepy 라이브러리](https://www.tweepy.org/)

---

이 가이드라인을 따라 X 크롤링&요약게시 기능을 개발하면, 기존 시스템에 영향 없이 안정적인 자동화 시스템을 구축할 수 있습니다.